{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XNQAbhjLdk3m"
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Om6ffAileLTu"
   },
   "outputs": [],
   "source": [
    "!pip install trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mppo_5\u001b[0m/  \u001b[01;34mppo_5.19\u001b[0m/  \u001b[01;34mppo_5.39\u001b[0m/  \u001b[01;34mppo_5.59\u001b[0m/  \u001b[01;34mppo_5.79\u001b[0m/  \u001b[01;34msft_5\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls ckpts_ppo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('transformer.wte.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0986, -0.0913,  0.0996,  ...,  0.0054,  0.0369,  0.0503],\n",
       "          [ 0.0493, -0.0869,  0.0649,  ..., -0.0192,  0.0066,  0.0011],\n",
       "          [ 0.0820, -0.0284,  0.0483,  ...,  0.0674, -0.0398,  0.0635],\n",
       "          ...,\n",
       "          [ 0.1260, -0.1465,  0.1709,  ...,  0.0270, -0.0708,  0.0850],\n",
       "          [-0.0096, -0.0806,  0.1230,  ...,  0.0566,  0.0728,  0.1240],\n",
       "          [ 0.0669, -0.0947,  0.0913,  ...,  0.0027, -0.0359,  0.0544]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.wpe.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0493, -0.0199,  0.0216,  ...,  0.0067, -0.1040,  0.0013],\n",
       "          [ 0.0087, -0.0840, -0.0062,  ...,  0.0186, -0.0508,  0.0001],\n",
       "          [ 0.0176, -0.0164, -0.0027,  ...,  0.0177, -0.0228,  0.0038],\n",
       "          ...,\n",
       "          [ 0.0123,  0.0369, -0.0210,  ...,  0.0216,  0.0364,  0.0206],\n",
       "          [ 0.0117,  0.0359, -0.0272,  ...,  0.0121,  0.0374,  0.0304],\n",
       "          [ 0.0181,  0.0293, -0.0209,  ...,  0.0306,  0.0347,  0.0288]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.0.ln_1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([0.2812, 0.1641, 0.2520,  ..., 0.3594, 0.1836, 0.2578],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.0.ln_1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.2227,  0.2559, -0.0500,  ..., -0.0649,  0.1040, -0.0913],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.0.attn.attention.k_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0244, -0.0264, -0.0811,  ...,  0.0359,  0.0464,  0.0835],\n",
       "          [ 0.0276, -0.0160, -0.0505,  ...,  0.0457,  0.0981, -0.0664],\n",
       "          [ 0.1016, -0.0084,  0.0364,  ..., -0.0513,  0.0132, -0.0884],\n",
       "          ...,\n",
       "          [-0.0557, -0.0903, -0.1543,  ..., -0.0211, -0.0045,  0.0752],\n",
       "          [-0.0112,  0.0918, -0.0557,  ...,  0.0432,  0.0771, -0.0076],\n",
       "          [ 0.0623,  0.0049,  0.0309,  ..., -0.0103,  0.0105, -0.0157]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.0.attn.attention.v_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0747,  0.0718, -0.0806,  ...,  0.0219,  0.0525,  0.0854],\n",
       "          [ 0.0021, -0.0239,  0.0693,  ..., -0.0121,  0.0562,  0.0312],\n",
       "          [ 0.0020, -0.0566,  0.0693,  ...,  0.0105,  0.0471,  0.0118],\n",
       "          ...,\n",
       "          [-0.0204,  0.0488,  0.1060,  ...,  0.0144,  0.0688, -0.0042],\n",
       "          [-0.0903, -0.0126,  0.0420,  ..., -0.0051,  0.1709, -0.0835],\n",
       "          [-0.0082, -0.0383, -0.0522,  ...,  0.0537, -0.0684, -0.0806]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.0.attn.attention.q_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0031, -0.0320, -0.1426,  ...,  0.0188, -0.0498,  0.0815],\n",
       "          [ 0.0415, -0.0801, -0.1338,  ...,  0.0162,  0.0659, -0.0684],\n",
       "          [ 0.0208, -0.0413,  0.0201,  ..., -0.0554,  0.0023,  0.0396],\n",
       "          ...,\n",
       "          [-0.0439,  0.0498, -0.1582,  ...,  0.0420, -0.1147,  0.0723],\n",
       "          [ 0.0038,  0.1084, -0.1074,  ...,  0.0898,  0.0752, -0.0337],\n",
       "          [ 0.0525, -0.0233,  0.0684,  ..., -0.0581,  0.0806, -0.0806]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.0.attn.attention.out_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0011, -0.0110, -0.0081,  ...,  0.0117, -0.0369,  0.0162],\n",
       "          [-0.0048, -0.0052, -0.0476,  ..., -0.0493,  0.0493, -0.0112],\n",
       "          [-0.1426,  0.0767,  0.0052,  ...,  0.0688, -0.1104, -0.0415],\n",
       "          ...,\n",
       "          [-0.0430,  0.0273,  0.0415,  ..., -0.0747,  0.0471, -0.0947],\n",
       "          [-0.0251,  0.0388,  0.0040,  ...,  0.0072, -0.0116, -0.0566],\n",
       "          [-0.0112,  0.0036, -0.0087,  ..., -0.1328, -0.0289, -0.1396]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.0.attn.attention.out_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0109, -0.0474,  0.0503,  ..., -0.0110, -0.0198, -0.0097],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.0.ln_2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([0.7500, 0.9180, 0.8047,  ..., 0.8672, 0.9805, 0.6797],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.0.ln_2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0679, -0.1094, -0.0050,  ...,  0.0806, -0.1084,  0.1177],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.0.mlp.c_fc.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0708,  0.0493, -0.0427,  ...,  0.0151,  0.1309, -0.0260],\n",
       "          [-0.0413, -0.0046, -0.0703,  ...,  0.1187,  0.0796, -0.0559],\n",
       "          [-0.1035, -0.0004, -0.0537,  ...,  0.0557,  0.0781, -0.1523],\n",
       "          ...,\n",
       "          [ 0.0229, -0.0106,  0.0243,  ...,  0.0219,  0.0015,  0.0625],\n",
       "          [-0.0344, -0.0518,  0.0330,  ...,  0.0630,  0.0100, -0.0618],\n",
       "          [-0.0747, -0.0128, -0.0635,  ..., -0.0165,  0.0247,  0.0093]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.0.mlp.c_fc.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0376,  0.0137, -0.0084,  ...,  0.1157,  0.0106, -0.0403],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.0.mlp.c_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0349, -0.0121,  0.0447,  ..., -0.0036,  0.0361,  0.0136],\n",
       "          [ 0.0564,  0.0625,  0.0845,  ..., -0.0050,  0.0039,  0.0125],\n",
       "          [-0.0359, -0.0574, -0.0253,  ..., -0.0070, -0.0072, -0.0227],\n",
       "          ...,\n",
       "          [-0.0186, -0.0217, -0.0130,  ...,  0.0012,  0.0457,  0.0212],\n",
       "          [-0.0110, -0.0109,  0.0520,  ..., -0.0095, -0.0840,  0.0139],\n",
       "          [-0.0311,  0.0220,  0.0209,  ..., -0.0030, -0.0077,  0.1367]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.0.mlp.c_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0635,  0.0698,  0.0569,  ..., -0.0337,  0.0579, -0.0469],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.1.ln_1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([0.4844, 0.5000, 0.4434,  ..., 0.4277, 0.5000, 0.4980],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.1.ln_1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0052, -0.0015, -0.0232,  ...,  0.0221,  0.0175,  0.0280],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.1.attn.attention.k_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0352, -0.1201, -0.0708,  ...,  0.0732,  0.0113, -0.0386],\n",
       "          [ 0.0728, -0.0757,  0.0269,  ...,  0.0532,  0.0918,  0.0344],\n",
       "          [-0.0471, -0.0178, -0.0342,  ..., -0.0249,  0.0098, -0.0051],\n",
       "          ...,\n",
       "          [ 0.1089,  0.0008, -0.0024,  ..., -0.0342,  0.0064, -0.0581],\n",
       "          [ 0.0283, -0.0193,  0.0859,  ...,  0.0106,  0.0618,  0.0752],\n",
       "          [-0.1133,  0.0579,  0.0171,  ...,  0.1934, -0.0344, -0.0535]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.1.attn.attention.v_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0117, -0.1357, -0.0898,  ..., -0.0537,  0.0410, -0.0571],\n",
       "          [ 0.0601,  0.0674,  0.0063,  ..., -0.0256,  0.0410, -0.0138],\n",
       "          [ 0.0339,  0.0144, -0.0693,  ..., -0.0640,  0.1104,  0.0077],\n",
       "          ...,\n",
       "          [ 0.0096,  0.0009, -0.0334,  ..., -0.0811, -0.0535, -0.0178],\n",
       "          [ 0.0864, -0.0369, -0.0075,  ...,  0.0040, -0.0645,  0.0481],\n",
       "          [ 0.0051, -0.1689,  0.0347,  ...,  0.0522,  0.0608,  0.0398]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.1.attn.attention.q_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0182, -0.0918, -0.0165,  ...,  0.0267, -0.0547,  0.0068],\n",
       "          [ 0.0366, -0.0278,  0.0776,  ...,  0.0449, -0.0520,  0.0583],\n",
       "          [-0.0043,  0.1069, -0.0262,  ..., -0.0243, -0.0089, -0.0244],\n",
       "          ...,\n",
       "          [-0.1133, -0.0315,  0.0352,  ..., -0.1211,  0.1206, -0.0297],\n",
       "          [-0.0469, -0.0132, -0.0203,  ..., -0.1338, -0.0801,  0.0134],\n",
       "          [-0.0189,  0.1177,  0.0080,  ...,  0.0947, -0.0142,  0.0374]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.1.attn.attention.out_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0303, -0.0339,  0.0036,  ..., -0.0369, -0.0942, -0.0247],\n",
       "          [ 0.0281,  0.0156, -0.0374,  ...,  0.0064, -0.0659,  0.0084],\n",
       "          [ 0.0615,  0.0364,  0.0786,  ...,  0.0718,  0.0496, -0.0317],\n",
       "          ...,\n",
       "          [-0.0337,  0.0197,  0.0481,  ...,  0.0601, -0.0625, -0.0413],\n",
       "          [ 0.0825, -0.0085, -0.0287,  ...,  0.0132, -0.0640,  0.0322],\n",
       "          [ 0.0386, -0.0364, -0.0859,  ..., -0.0732, -0.0840,  0.0549]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.1.attn.attention.out_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0593,  0.0420,  0.0698,  ..., -0.0344,  0.0593, -0.0593],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.1.ln_2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([1.2031, 1.6719, 1.2422,  ..., 1.2891, 1.2500, 1.3594],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.1.ln_2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0166,  0.1436, -0.0391,  ..., -0.0229,  0.0168, -0.0469],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.1.mlp.c_fc.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0004, -0.1035,  0.0320,  ..., -0.0203,  0.1201,  0.0520],\n",
       "          [-0.1104,  0.0189,  0.0103,  ...,  0.0840, -0.1650, -0.0742],\n",
       "          [-0.0210,  0.0771, -0.0248,  ..., -0.0132, -0.0549, -0.0171],\n",
       "          ...,\n",
       "          [ 0.0620, -0.0618, -0.0315,  ...,  0.0659,  0.0576,  0.0400],\n",
       "          [ 0.0112, -0.1191,  0.0047,  ..., -0.0248, -0.0337,  0.0173],\n",
       "          [ 0.0042, -0.1147, -0.0483,  ...,  0.2227, -0.0640, -0.0066]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.1.mlp.c_fc.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0129, -0.0222, -0.0087,  ..., -0.0256,  0.0095, -0.0254],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.1.mlp.c_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0070, -0.0459,  0.0076,  ...,  0.0718, -0.0408,  0.0179],\n",
       "          [-0.0505, -0.1514,  0.0160,  ..., -0.0884, -0.1006,  0.0579],\n",
       "          [ 0.0122, -0.0359, -0.0095,  ..., -0.0425,  0.0315, -0.0156],\n",
       "          ...,\n",
       "          [-0.0415,  0.0332,  0.0023,  ...,  0.0121,  0.0635, -0.0562],\n",
       "          [ 0.0184, -0.0815, -0.0153,  ...,  0.0344, -0.0349, -0.0464],\n",
       "          [-0.0337, -0.0117, -0.0510,  ..., -0.0544,  0.0444, -0.0118]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.1.mlp.c_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0481, -0.0168,  0.0718,  ..., -0.0172,  0.0291, -0.0405],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.2.ln_1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([0.5742, 0.5977, 0.5430,  ..., 0.5820, 0.5664, 0.5859],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.2.ln_1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0173, -0.0215, -0.0093,  ...,  0.0219,  0.0283,  0.0113],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.2.attn.attention.k_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0732, -0.1162,  0.0947,  ..., -0.0693, -0.0796,  0.0625],\n",
       "          [-0.0530, -0.1089,  0.1875,  ..., -0.0520,  0.0146, -0.0801],\n",
       "          [-0.0469, -0.0684, -0.0184,  ..., -0.0293,  0.0403,  0.0334],\n",
       "          ...,\n",
       "          [-0.0354,  0.0134, -0.0942,  ...,  0.0317, -0.0869,  0.0938],\n",
       "          [ 0.0166,  0.0019,  0.0359,  ..., -0.0603, -0.0757, -0.0140],\n",
       "          [-0.0579,  0.0737,  0.0388,  ..., -0.1113, -0.0693,  0.0192]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.2.attn.attention.v_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0542,  0.0016,  0.0298,  ...,  0.0879,  0.1191, -0.0225],\n",
       "          [-0.0073, -0.0347, -0.0510,  ...,  0.0498, -0.0151,  0.0500],\n",
       "          [ 0.0089, -0.0147, -0.0030,  ..., -0.0859, -0.0752,  0.0243],\n",
       "          ...,\n",
       "          [ 0.0084,  0.0496, -0.0061,  ...,  0.0177, -0.0074, -0.0356],\n",
       "          [ 0.0033,  0.0048, -0.0752,  ...,  0.0894,  0.0223, -0.0188],\n",
       "          [ 0.0630, -0.0315, -0.0757,  ..., -0.0081,  0.0073, -0.1211]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.2.attn.attention.q_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0095,  0.0967, -0.0016,  ...,  0.1777,  0.0830,  0.0635],\n",
       "          [ 0.0216, -0.0500, -0.0898,  ..., -0.0178, -0.0723,  0.0781],\n",
       "          [-0.1089,  0.0466, -0.0669,  ...,  0.0452,  0.1445,  0.0820],\n",
       "          ...,\n",
       "          [ 0.0033, -0.1797, -0.0127,  ..., -0.1582,  0.0938,  0.0623],\n",
       "          [-0.0388,  0.0649,  0.0510,  ...,  0.0835, -0.0168, -0.0952],\n",
       "          [ 0.0452,  0.0942, -0.0201,  ..., -0.0908,  0.0210,  0.0249]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.2.attn.attention.out_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0742, -0.0403,  0.0908,  ..., -0.0017,  0.0552, -0.1138],\n",
       "          [-0.0308, -0.0236, -0.1074,  ...,  0.0688, -0.1152, -0.0679],\n",
       "          [ 0.0403,  0.1147,  0.1436,  ..., -0.0547,  0.0334, -0.0762],\n",
       "          ...,\n",
       "          [-0.0791,  0.0162, -0.0483,  ...,  0.0645,  0.0398, -0.0155],\n",
       "          [-0.0190,  0.0205,  0.0464,  ..., -0.0160,  0.0061,  0.1338],\n",
       "          [-0.0287,  0.0342,  0.0283,  ...,  0.0332, -0.0186,  0.0874]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.2.attn.attention.out_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0510, -0.0280,  0.0811,  ..., -0.0124,  0.0144, -0.0216],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.2.ln_2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([1.3047, 1.4531, 1.3125,  ..., 1.1719, 1.3125, 1.1953],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.2.ln_2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0004,  0.0618,  0.0498,  ..., -0.0566,  0.0493,  0.0118],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.2.mlp.c_fc.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0088,  0.0957,  0.0581,  ...,  0.1523,  0.0510,  0.0439],\n",
       "          [-0.0041, -0.0664,  0.0354,  ..., -0.0334, -0.0172, -0.0047],\n",
       "          [ 0.0898,  0.0315, -0.2324,  ...,  0.1030,  0.0693,  0.1270],\n",
       "          ...,\n",
       "          [ 0.1484, -0.0552, -0.0903,  ..., -0.0309,  0.0410, -0.0099],\n",
       "          [ 0.0544, -0.0476, -0.0106,  ...,  0.1074,  0.0388, -0.0187],\n",
       "          [-0.0201, -0.0537, -0.1177,  ...,  0.0688,  0.0393,  0.0125]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.2.mlp.c_fc.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0133, -0.0122, -0.0212,  ..., -0.0238, -0.0417, -0.0293],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.2.mlp.c_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0928, -0.0093,  0.0209,  ..., -0.0095, -0.0515,  0.0864],\n",
       "          [-0.0110,  0.0017,  0.0417,  ...,  0.0245,  0.0007,  0.0957],\n",
       "          [ 0.0461, -0.0075, -0.0317,  ...,  0.0591, -0.0173, -0.0464],\n",
       "          ...,\n",
       "          [-0.0037, -0.0067,  0.0649,  ..., -0.0275,  0.0093,  0.0493],\n",
       "          [ 0.1045,  0.0087,  0.0153,  ...,  0.1445, -0.0070,  0.0728],\n",
       "          [-0.0576,  0.0457, -0.0576,  ...,  0.1152,  0.0195,  0.0102]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.2.mlp.c_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0464, -0.0175,  0.0625,  ...,  0.0237, -0.0172, -0.0090],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.3.ln_1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([0.4688, 0.4082, 0.3770,  ..., 0.4805, 0.4609, 0.5000],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.3.ln_1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0195, -0.0200,  0.0142,  ...,  0.0051,  0.0101, -0.0099],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.3.attn.attention.k_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 2.2827e-02, -4.0039e-02, -6.1035e-02,  ..., -4.8584e-02,\n",
       "           -9.6680e-02,  3.2471e-02],\n",
       "          [ 8.8867e-02,  8.4473e-02,  5.4199e-02,  ..., -3.1494e-02,\n",
       "            1.7929e-03, -1.0252e-04],\n",
       "          [-3.2471e-02,  7.0312e-02, -1.3794e-02,  ...,  3.1982e-02,\n",
       "            5.0781e-02, -1.4954e-02],\n",
       "          ...,\n",
       "          [ 8.8379e-02, -3.1006e-02, -2.4414e-02,  ..., -8.0566e-03,\n",
       "           -1.2305e-01, -9.6191e-02],\n",
       "          [ 8.4961e-02, -7.4707e-02, -6.3782e-03,  ...,  1.0681e-02,\n",
       "            1.0498e-02,  5.4932e-02],\n",
       "          [ 5.5908e-02, -4.6387e-02, -1.4526e-02,  ...,  3.5156e-02,\n",
       "           -2.2949e-02, -3.4424e-02]], requires_grad=True)),\n",
       " ('transformer.h.3.attn.attention.v_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 2.6398e-03, -2.2461e-02, -5.7373e-02,  ..., -2.1362e-02,\n",
       "            5.3711e-02,  1.9653e-02],\n",
       "          [ 3.7109e-02,  8.2520e-02,  1.8262e-01,  ...,  5.4443e-02,\n",
       "           -1.8311e-02, -1.4551e-01],\n",
       "          [ 5.0537e-02, -7.9590e-02,  7.7637e-02,  ..., -7.1777e-02,\n",
       "           -1.3000e-02,  9.4727e-02],\n",
       "          ...,\n",
       "          [ 1.0254e-02, -1.0059e-01,  2.6001e-02,  ..., -2.2949e-02,\n",
       "            5.7602e-04, -2.5024e-02],\n",
       "          [-3.8086e-02,  1.4343e-02,  6.9336e-02,  ...,  4.9805e-02,\n",
       "            3.6621e-02, -1.8024e-04],\n",
       "          [-9.1797e-02, -3.5889e-02, -6.2012e-02,  ..., -8.1543e-02,\n",
       "            1.0596e-01,  5.1025e-02]], requires_grad=True)),\n",
       " ('transformer.h.3.attn.attention.q_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0503,  0.0221,  0.1226,  ..., -0.0214,  0.0137, -0.0552],\n",
       "          [-0.0332, -0.0566, -0.1660,  ...,  0.0742, -0.0193,  0.0718],\n",
       "          [ 0.0928, -0.0069, -0.0173,  ...,  0.0309, -0.0718,  0.0354],\n",
       "          ...,\n",
       "          [ 0.0334,  0.0669, -0.0148,  ...,  0.0752,  0.0933, -0.0515],\n",
       "          [ 0.0413,  0.0811,  0.1416,  ...,  0.0261,  0.0095, -0.0049],\n",
       "          [-0.0189,  0.0623, -0.0247,  ..., -0.0098, -0.0197, -0.0043]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.3.attn.attention.out_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0503, -0.0620, -0.0781,  ...,  0.0009,  0.0645, -0.0027],\n",
       "          [-0.0620, -0.0238,  0.0361,  ...,  0.1621, -0.1030, -0.1357],\n",
       "          [ 0.1572,  0.0155,  0.0503,  ..., -0.0254, -0.0498,  0.0659],\n",
       "          ...,\n",
       "          [ 0.0053,  0.0219,  0.0742,  ...,  0.0139,  0.0194, -0.0486],\n",
       "          [-0.1348,  0.0209,  0.0236,  ..., -0.0386,  0.0167, -0.0620],\n",
       "          [-0.0815,  0.1182,  0.0630,  ..., -0.0762,  0.0286, -0.0325]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.3.attn.attention.out_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0344,  0.0002,  0.0815,  ..., -0.0422, -0.0010,  0.0004],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.3.ln_2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([0.9961, 1.0703, 1.0859,  ..., 1.0000, 1.1562, 1.0234],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.3.ln_2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0031, -0.0009,  0.0056,  ...,  0.0132,  0.0269,  0.0050],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.3.mlp.c_fc.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0439,  0.0118,  0.0251,  ...,  0.0289,  0.0547,  0.0022],\n",
       "          [ 0.0005,  0.0204, -0.0200,  ...,  0.0010, -0.0067,  0.0192],\n",
       "          [ 0.0737, -0.0140,  0.0262,  ...,  0.0493, -0.0062, -0.1455],\n",
       "          ...,\n",
       "          [ 0.0664,  0.0122,  0.0325,  ..., -0.0215,  0.0254, -0.0253],\n",
       "          [-0.0085, -0.0048,  0.0220,  ..., -0.0344, -0.0072,  0.0119],\n",
       "          [-0.0112, -0.0131,  0.0183,  ...,  0.0293,  0.0280, -0.0162]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.3.mlp.c_fc.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0040, -0.0442, -0.0698,  ..., -0.0189,  0.0084, -0.0347],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.3.mlp.c_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0034,  0.0184, -0.0544,  ..., -0.0366,  0.0084,  0.0088],\n",
       "          [ 0.0160, -0.0012,  0.0422,  ..., -0.0216,  0.0047,  0.0033],\n",
       "          [-0.0038, -0.0126,  0.0381,  ..., -0.0240, -0.0104,  0.0070],\n",
       "          ...,\n",
       "          [-0.0012,  0.0097, -0.0011,  ...,  0.0219,  0.0101,  0.0088],\n",
       "          [-0.0291,  0.0009, -0.0216,  ..., -0.0017,  0.0015, -0.0042],\n",
       "          [ 0.0075,  0.0019,  0.0337,  ..., -0.0102, -0.0055,  0.0006]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.3.mlp.c_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0315,  0.0167,  0.0742,  ..., -0.0310, -0.0109,  0.0038],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.4.ln_1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([0.6719, 0.6953, 0.6719,  ..., 0.6680, 0.7227, 0.7227],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.4.ln_1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0173, -0.0150,  0.0014,  ...,  0.0208,  0.0225, -0.0088],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.4.attn.attention.k_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0036, -0.0649, -0.0118,  ..., -0.0332,  0.0069, -0.0112],\n",
       "          [-0.0045, -0.1758, -0.0952,  ...,  0.1060, -0.0065,  0.0356],\n",
       "          [-0.0260, -0.0036, -0.0168,  ...,  0.0014, -0.0008, -0.0173],\n",
       "          ...,\n",
       "          [ 0.0564, -0.0571, -0.0603,  ...,  0.0854,  0.0635, -0.0405],\n",
       "          [ 0.0432, -0.0300,  0.0022,  ...,  0.0188,  0.0123,  0.0708],\n",
       "          [ 0.0245, -0.0952,  0.0408,  ...,  0.0806, -0.0432, -0.0286]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.4.attn.attention.v_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0996, -0.0037, -0.0747,  ..., -0.0439, -0.0265, -0.0469],\n",
       "          [ 0.1152, -0.0100, -0.1260,  ..., -0.0051, -0.0115, -0.1240],\n",
       "          [-0.0708, -0.1133,  0.0698,  ..., -0.0737,  0.0449,  0.0815],\n",
       "          ...,\n",
       "          [-0.0552,  0.1309,  0.0206,  ...,  0.0253, -0.0410,  0.1270],\n",
       "          [-0.0913, -0.1162, -0.0903,  ...,  0.0209, -0.0520, -0.0067],\n",
       "          [-0.0178,  0.0435,  0.0109,  ..., -0.0032, -0.0120,  0.0334]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.4.attn.attention.q_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1196, -0.1377,  0.1260,  ..., -0.0107,  0.0481,  0.0427],\n",
       "          [ 0.0845, -0.0972, -0.0728,  ..., -0.0020,  0.0347, -0.0181],\n",
       "          [ 0.0107, -0.1157, -0.0225,  ..., -0.1504, -0.0383, -0.0825],\n",
       "          ...,\n",
       "          [ 0.0364, -0.0532, -0.0122,  ..., -0.0107,  0.0194, -0.0189],\n",
       "          [-0.0659,  0.0334, -0.1367,  ..., -0.0483, -0.0713,  0.0251],\n",
       "          [-0.0593,  0.0221,  0.0273,  ..., -0.1099,  0.0913,  0.0194]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.4.attn.attention.out_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 4.8584e-02, -1.0693e-01,  8.9844e-02,  ...,  4.6875e-02,\n",
       "            2.2583e-03,  5.5695e-04],\n",
       "          [ 6.2012e-02,  7.1106e-03, -1.1963e-02,  ..., -1.0693e-01,\n",
       "            1.6212e-04, -1.1475e-02],\n",
       "          [-1.2512e-02,  9.8145e-02, -5.1880e-03,  ...,  1.1292e-02,\n",
       "           -3.7109e-02, -3.2227e-02],\n",
       "          ...,\n",
       "          [ 4.8523e-03,  8.4473e-02,  7.1106e-03,  ..., -7.7148e-02,\n",
       "            5.6641e-02,  4.5410e-02],\n",
       "          [-6.2500e-02,  1.2207e-02,  4.8584e-02,  ...,  3.2715e-02,\n",
       "           -7.4707e-02, -2.0905e-03],\n",
       "          [-6.7383e-02,  6.8848e-02, -1.7480e-01,  ..., -1.9287e-02,\n",
       "            4.8065e-04, -2.4872e-03]], requires_grad=True)),\n",
       " ('transformer.h.4.attn.attention.out_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0219,  0.0229,  0.0493,  ..., -0.0095, -0.0179,  0.0240],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.4.ln_2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([1.4453, 1.6875, 1.5703,  ..., 1.5234, 1.5547, 1.5000],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.4.ln_2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0.0294, 0.0371, 0.0227,  ..., 0.0315, 0.0272, 0.0120],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.4.mlp.c_fc.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0225, -0.0400,  0.0093,  ..., -0.0537, -0.0488, -0.0193],\n",
       "          [ 0.0481, -0.1064, -0.0014,  ..., -0.0132,  0.0442, -0.0203],\n",
       "          [ 0.0898,  0.0415,  0.0493,  ...,  0.0464, -0.1367,  0.0557],\n",
       "          ...,\n",
       "          [-0.0212,  0.0032,  0.1001,  ...,  0.0066,  0.0894,  0.0223],\n",
       "          [-0.0776, -0.0476,  0.0613,  ...,  0.0977, -0.0806,  0.0811],\n",
       "          [-0.0413, -0.1104, -0.0786,  ...,  0.0859, -0.1240, -0.0150]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.4.mlp.c_fc.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0060, -0.0850, -0.0303,  ..., -0.0234, -0.0193, -0.0306],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.4.mlp.c_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0197,  0.1670,  0.0593,  ..., -0.0630,  0.0298,  0.0437],\n",
       "          [-0.0092, -0.0111,  0.0139,  ..., -0.0669, -0.0214,  0.0410],\n",
       "          [-0.0082, -0.0879,  0.0201,  ...,  0.0476,  0.0554,  0.0481],\n",
       "          ...,\n",
       "          [ 0.0461, -0.1201,  0.0527,  ..., -0.0815, -0.0056,  0.0603],\n",
       "          [ 0.0266,  0.1108,  0.0302,  ...,  0.0562,  0.0300,  0.0022],\n",
       "          [ 0.0264, -0.0012, -0.0020,  ..., -0.0728, -0.0238,  0.0149]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.4.mlp.c_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0164,  0.0325,  0.0457,  ..., -0.0066, -0.0047,  0.0104],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.5.ln_1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([0.6719, 0.7305, 0.7344,  ..., 0.7422, 0.7266, 0.6836],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.5.ln_1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0413, -0.0220,  0.0107,  ...,  0.0349,  0.0201,  0.0084],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.5.attn.attention.k_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0540, -0.0035,  0.0029,  ...,  0.0173, -0.0281,  0.0532],\n",
       "          [ 0.0162,  0.0898, -0.0845,  ...,  0.0535, -0.0588,  0.0435],\n",
       "          [-0.0133,  0.0237,  0.0698,  ..., -0.0198, -0.0173, -0.0082],\n",
       "          ...,\n",
       "          [ 0.0216,  0.0471,  0.1396,  ...,  0.0084, -0.1104,  0.0029],\n",
       "          [-0.0176, -0.0245, -0.0388,  ..., -0.0723,  0.0583, -0.0334],\n",
       "          [-0.0258, -0.1348, -0.0332,  ...,  0.0337,  0.0327, -0.0942]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.5.attn.attention.v_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0413,  0.0381, -0.0197,  ..., -0.0159, -0.0327,  0.0957],\n",
       "          [-0.0415,  0.0898, -0.0486,  ...,  0.0601,  0.0300, -0.0339],\n",
       "          [-0.0471, -0.0801,  0.1196,  ..., -0.0146,  0.1729, -0.0508],\n",
       "          ...,\n",
       "          [-0.0041,  0.0269, -0.0194,  ..., -0.0187, -0.1143,  0.0064],\n",
       "          [-0.0249, -0.0806,  0.1055,  ..., -0.0182, -0.0471,  0.0240],\n",
       "          [ 0.0913, -0.0215,  0.0129,  ...,  0.0391,  0.0214,  0.0703]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.5.attn.attention.q_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 7.5684e-02,  1.1475e-01,  5.2979e-02,  ..., -1.9932e-04,\n",
       "           -6.7871e-02, -3.3936e-02],\n",
       "          [-3.1738e-02,  1.0840e-01,  6.6223e-03,  ...,  7.3730e-02,\n",
       "           -2.4536e-02, -6.1523e-02],\n",
       "          [-4.1504e-02,  8.4839e-03, -4.6875e-02,  ...,  7.6660e-02,\n",
       "            5.3406e-03,  6.4087e-03],\n",
       "          ...,\n",
       "          [-1.9409e-02,  8.3984e-02,  1.4453e-01,  ..., -6.7139e-03,\n",
       "           -2.2125e-03, -3.8330e-02],\n",
       "          [-1.4453e-01,  6.0303e-02, -2.7832e-02,  ...,  6.7383e-02,\n",
       "            2.4023e-01, -8.0566e-02],\n",
       "          [ 3.1128e-02,  4.4189e-02, -1.2354e-01,  ...,  4.7607e-02,\n",
       "            9.0820e-02,  1.1670e-01]], requires_grad=True)),\n",
       " ('transformer.h.5.attn.attention.out_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0069, -0.0090,  0.0172,  ...,  0.0164, -0.0219, -0.1069],\n",
       "          [-0.0391, -0.0630,  0.0067,  ..., -0.1230,  0.0197,  0.0549],\n",
       "          [-0.0713,  0.0457, -0.0084,  ..., -0.0065, -0.0781, -0.0698],\n",
       "          ...,\n",
       "          [ 0.0605,  0.0361, -0.0718,  ...,  0.0757,  0.0203, -0.0140],\n",
       "          [ 0.0435, -0.0334, -0.0688,  ...,  0.1396, -0.0165, -0.0591],\n",
       "          [-0.0767,  0.0923,  0.0036,  ..., -0.0334, -0.0544,  0.0908]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.5.attn.attention.out_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0145,  0.0413,  0.0298,  ..., -0.0177, -0.0154,  0.0170],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.5.ln_2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([1.6562, 2.0000, 1.7422,  ..., 1.7344, 1.7500, 1.7500],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.5.ln_2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0.0903, 0.0830, 0.0659,  ..., 0.0757, 0.0270, 0.0796],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.5.mlp.c_fc.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0051,  0.0542, -0.0056,  ...,  0.1396,  0.1113,  0.0105],\n",
       "          [ 0.0332,  0.0801,  0.1050,  ...,  0.1260,  0.1387, -0.0508],\n",
       "          [-0.0476,  0.0623, -0.0312,  ...,  0.0342, -0.0282, -0.0400],\n",
       "          ...,\n",
       "          [ 0.1025,  0.0262, -0.0238,  ..., -0.1016,  0.0923, -0.1196],\n",
       "          [ 0.0679,  0.0366, -0.1318,  ...,  0.1118,  0.0549,  0.0297],\n",
       "          [-0.0021, -0.0247, -0.0148,  ...,  0.1836,  0.0040, -0.0032]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.5.mlp.c_fc.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0216, -0.0038, -0.0114,  ..., -0.0248, -0.0132, -0.0221],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.5.mlp.c_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0674,  0.0199,  0.0854,  ..., -0.0142,  0.1030, -0.1309],\n",
       "          [-0.0220,  0.1016, -0.0574,  ...,  0.0623, -0.0918, -0.0260],\n",
       "          [-0.0142, -0.0204, -0.0106,  ..., -0.0605, -0.0244,  0.0226],\n",
       "          ...,\n",
       "          [ 0.0112, -0.0044, -0.0223,  ...,  0.0293,  0.0898, -0.0374],\n",
       "          [ 0.0084, -0.0732, -0.0496,  ...,  0.1455, -0.0109, -0.0096],\n",
       "          [ 0.0137, -0.0889, -0.0058,  ...,  0.1543, -0.1167, -0.0640]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.5.mlp.c_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0352,  0.0334,  0.0310,  ..., -0.0332, -0.0058,  0.0181],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.6.ln_1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([0.6875, 0.7539, 0.7969,  ..., 0.7383, 0.7422, 0.7344],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.6.ln_1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0.0405, 0.0128, 0.0320,  ..., 0.0159, 0.0226, 0.0160],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.6.attn.attention.k_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0278, -0.1177, -0.0209,  ...,  0.0791,  0.0586, -0.0398],\n",
       "          [-0.0168,  0.0708, -0.0085,  ..., -0.0864,  0.0217,  0.0112],\n",
       "          [-0.0894,  0.0334, -0.0322,  ...,  0.0571, -0.1504, -0.0505],\n",
       "          ...,\n",
       "          [ 0.0474, -0.0120,  0.0250,  ..., -0.1206,  0.0352, -0.0654],\n",
       "          [ 0.0452,  0.0171, -0.0225,  ..., -0.0197,  0.0172,  0.0160],\n",
       "          [ 0.0167,  0.0396, -0.1191,  ...,  0.0732, -0.0031,  0.0243]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.6.attn.attention.v_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1758, -0.0554, -0.0679,  ...,  0.0141, -0.0388, -0.0732],\n",
       "          [-0.0105, -0.0219, -0.0006,  ...,  0.0228,  0.0124, -0.1113],\n",
       "          [-0.0317,  0.0094, -0.0089,  ...,  0.0125,  0.0737,  0.0776],\n",
       "          ...,\n",
       "          [-0.0898, -0.0693,  0.1562,  ...,  0.0811, -0.0352,  0.0005],\n",
       "          [ 0.2031,  0.0208,  0.0723,  ..., -0.0835,  0.0703,  0.0437],\n",
       "          [-0.0115, -0.0325, -0.0349,  ..., -0.1279,  0.0869,  0.0087]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.6.attn.attention.q_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0723, -0.0278,  0.0172,  ...,  0.0222, -0.0378, -0.0173],\n",
       "          [ 0.0261,  0.0325, -0.0903,  ...,  0.0903, -0.0400, -0.1211],\n",
       "          [ 0.0374,  0.0371,  0.0184,  ...,  0.0047, -0.0393, -0.0417],\n",
       "          ...,\n",
       "          [ 0.0444, -0.0457,  0.0030,  ...,  0.0449,  0.0096,  0.0081],\n",
       "          [-0.0476, -0.0898,  0.1235,  ..., -0.0293, -0.1216,  0.0776],\n",
       "          [ 0.0669,  0.1797,  0.0374,  ..., -0.0608,  0.0791, -0.0903]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.6.attn.attention.out_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0408,  0.0063,  0.1904,  ...,  0.0869, -0.0913, -0.1523],\n",
       "          [ 0.0850, -0.1396, -0.0481,  ...,  0.0913, -0.0645,  0.0206],\n",
       "          [-0.0095,  0.0300,  0.0771,  ..., -0.1377, -0.0117, -0.0036],\n",
       "          ...,\n",
       "          [ 0.0747,  0.0064, -0.0178,  ..., -0.0801,  0.0850, -0.0344],\n",
       "          [-0.0037,  0.0048, -0.0479,  ...,  0.0277, -0.0043,  0.1338],\n",
       "          [-0.0625,  0.0023,  0.0052,  ...,  0.0311, -0.0206, -0.0347]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.6.attn.attention.out_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0398,  0.0175,  0.0120,  ..., -0.0391, -0.0175,  0.0096],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.6.ln_2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([1.6484, 1.8047, 1.7109,  ..., 1.7422, 1.6797, 1.7109],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.6.ln_2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0.0593, 0.1387, 0.0471,  ..., 0.0146, 0.0405, 0.0679],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.6.mlp.c_fc.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0757, -0.0216,  0.1309,  ...,  0.0549, -0.1318, -0.0189],\n",
       "          [ 0.0967,  0.0025, -0.1235,  ...,  0.0222,  0.0752, -0.1426],\n",
       "          [-0.0708, -0.0649, -0.0396,  ...,  0.0067, -0.0498,  0.0444],\n",
       "          ...,\n",
       "          [-0.0006, -0.0388,  0.1260,  ...,  0.0398, -0.0025,  0.0564],\n",
       "          [-0.0079,  0.0300,  0.0996,  ...,  0.1123,  0.0214,  0.1709],\n",
       "          [-0.0564, -0.0084,  0.0142,  ...,  0.0520,  0.0801, -0.0579]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.6.mlp.c_fc.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0066, -0.0251, -0.0364,  ..., -0.0096, -0.0260, -0.0166],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.6.mlp.c_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0236, -0.0544, -0.0084,  ..., -0.0142, -0.0251, -0.0303],\n",
       "          [-0.0728, -0.1025, -0.0018,  ...,  0.0339, -0.0070, -0.0195],\n",
       "          [ 0.0025,  0.0618,  0.0620,  ..., -0.1172, -0.0781, -0.0576],\n",
       "          ...,\n",
       "          [-0.0435, -0.0134,  0.0162,  ..., -0.0349,  0.0566, -0.0281],\n",
       "          [ 0.0277,  0.0056,  0.0354,  ...,  0.0240,  0.0097, -0.0796],\n",
       "          [ 0.0815,  0.0811, -0.0732,  ..., -0.0352,  0.0020, -0.0378]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.6.mlp.c_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0596, -0.0160,  0.0092,  ..., -0.0251, -0.0076, -0.0090],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.7.ln_1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([0.7383, 0.7305, 0.7852,  ..., 0.7344, 0.7578, 0.7539],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.7.ln_1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0403, -0.0050,  0.0452,  ...,  0.0265,  0.0376, -0.0330],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.7.attn.attention.k_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0620,  0.0133,  0.0830,  ..., -0.0181,  0.0537, -0.0525],\n",
       "          [-0.0330,  0.0464,  0.0476,  ..., -0.0996,  0.0232,  0.0557],\n",
       "          [ 0.0413, -0.0854, -0.0030,  ..., -0.0107,  0.1416, -0.0698],\n",
       "          ...,\n",
       "          [ 0.0315, -0.0133, -0.0747,  ..., -0.0037, -0.0071, -0.0693],\n",
       "          [-0.0091, -0.0393, -0.0173,  ..., -0.1050, -0.0312, -0.0250],\n",
       "          [ 0.0294, -0.0544,  0.1074,  ..., -0.0640,  0.0137, -0.0010]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.7.attn.attention.v_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0003, -0.0276,  0.0623,  ...,  0.0056,  0.0193,  0.0198],\n",
       "          [ 0.1514,  0.0084, -0.0251,  ...,  0.0327, -0.0032,  0.0229],\n",
       "          [ 0.0615,  0.0825,  0.0674,  ...,  0.0315, -0.1230, -0.0181],\n",
       "          ...,\n",
       "          [-0.0776,  0.0064,  0.0845,  ..., -0.1641, -0.0757, -0.0408],\n",
       "          [ 0.0674,  0.0361, -0.0503,  ..., -0.1162, -0.0072,  0.1748],\n",
       "          [ 0.0166,  0.0400,  0.1045,  ..., -0.0249, -0.0287, -0.0874]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.7.attn.attention.q_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0150,  0.0162,  0.1021,  ..., -0.1035, -0.0688, -0.1050],\n",
       "          [-0.0703, -0.0679, -0.0649,  ..., -0.0674, -0.0117, -0.0021],\n",
       "          [-0.0479, -0.0903,  0.0427,  ..., -0.0449, -0.0586, -0.1387],\n",
       "          ...,\n",
       "          [ 0.0023,  0.1152,  0.1030,  ...,  0.0146, -0.0483, -0.0598],\n",
       "          [ 0.0645, -0.0249, -0.0061,  ..., -0.0361,  0.0189, -0.0618],\n",
       "          [-0.0096,  0.0391, -0.1187,  ..., -0.0152, -0.1021, -0.0532]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.7.attn.attention.out_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1138,  0.0942, -0.0255,  ..., -0.0569, -0.1138,  0.0167],\n",
       "          [ 0.0057, -0.0170, -0.0767,  ..., -0.0771,  0.0300,  0.0190],\n",
       "          [-0.0297, -0.0287,  0.0913,  ...,  0.0103,  0.0306, -0.0576],\n",
       "          ...,\n",
       "          [-0.0109, -0.0457,  0.0109,  ..., -0.0177,  0.1074, -0.0752],\n",
       "          [ 0.0618,  0.0244, -0.1147,  ..., -0.0527, -0.0835,  0.0425],\n",
       "          [ 0.0192,  0.0149, -0.0064,  ...,  0.0500, -0.0023, -0.0126]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.7.attn.attention.out_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0659, -0.0065, -0.0082,  ..., -0.0255, -0.0137,  0.0262],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.7.ln_2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([1.3906, 1.4531, 1.4922,  ..., 1.4141, 1.4297, 1.4219],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.7.ln_2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0513,  0.0320,  0.0194,  ...,  0.0508,  0.0347, -0.0210],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.7.mlp.c_fc.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0101,  0.0781,  0.0215,  ..., -0.0037,  0.0130,  0.1050],\n",
       "          [ 0.0065,  0.0918, -0.0082,  ...,  0.0209,  0.0923, -0.0342],\n",
       "          [ 0.0801, -0.0309,  0.0854,  ...,  0.0625,  0.0280, -0.0030],\n",
       "          ...,\n",
       "          [ 0.0593, -0.0952,  0.0172,  ..., -0.0645,  0.0640,  0.0559],\n",
       "          [-0.1001, -0.0272,  0.0469,  ..., -0.1289, -0.0562, -0.0347],\n",
       "          [ 0.0408, -0.0525,  0.0078,  ..., -0.0165, -0.0093,  0.0693]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.7.mlp.c_fc.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0304, -0.0020, -0.0162,  ..., -0.0396, -0.0287, -0.0420],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.7.mlp.c_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0398, -0.0330,  0.0493,  ...,  0.0312,  0.0352,  0.0623],\n",
       "          [-0.0081, -0.0391, -0.0547,  ..., -0.0388,  0.0281,  0.0292],\n",
       "          [-0.0388,  0.0996, -0.0854,  ..., -0.0114,  0.0437, -0.0175],\n",
       "          ...,\n",
       "          [ 0.0488,  0.0354, -0.0713,  ...,  0.0518, -0.1387,  0.0057],\n",
       "          [-0.0503, -0.0464,  0.1030,  ..., -0.0889, -0.0447, -0.0771],\n",
       "          [ 0.0021,  0.0175, -0.0208,  ..., -0.0010,  0.0713,  0.0466]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.7.mlp.c_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0698, -0.0022, -0.0072,  ..., -0.0298, -0.0214,  0.0354],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.8.ln_1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([0.7109, 0.7461, 0.7852,  ..., 0.7305, 0.7617, 0.7578],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.8.ln_1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0058, -0.0052,  0.0071,  ...,  0.0270,  0.0317,  0.0067],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.8.attn.attention.k_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1245, -0.0649, -0.0188,  ...,  0.0244,  0.0264, -0.0583],\n",
       "          [ 0.0635, -0.0422, -0.1030,  ..., -0.0679,  0.0125,  0.0605],\n",
       "          [ 0.0525,  0.0840, -0.0432,  ...,  0.0664,  0.0231, -0.0413],\n",
       "          ...,\n",
       "          [ 0.0259,  0.0303,  0.1885,  ...,  0.0986,  0.0400,  0.1299],\n",
       "          [-0.0176,  0.0244,  0.0079,  ..., -0.0454,  0.0027,  0.0796],\n",
       "          [ 0.0554, -0.0403, -0.1191,  ...,  0.0496, -0.0391, -0.0271]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.8.attn.attention.v_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 1.5137e-01, -1.2598e-01,  9.1309e-02,  ...,  6.6895e-02,\n",
       "            4.3701e-02, -5.7983e-03],\n",
       "          [-3.0029e-02,  2.0142e-02,  3.3936e-02,  ..., -1.4648e-02,\n",
       "           -5.7373e-02,  4.6631e-02],\n",
       "          [-1.2109e-01,  4.4189e-02, -3.1982e-02,  ..., -3.7109e-02,\n",
       "            1.1230e-02, -6.1279e-02],\n",
       "          ...,\n",
       "          [ 1.4282e-02,  1.0376e-02, -8.7891e-02,  ...,  6.1951e-03,\n",
       "           -1.9531e-02,  8.5449e-02],\n",
       "          [ 6.5002e-03, -9.3384e-03, -2.9663e-02,  ...,  1.0681e-04,\n",
       "            9.7656e-03, -4.4922e-02],\n",
       "          [-2.7539e-01, -2.3499e-03,  8.6670e-03,  ...,  3.3936e-02,\n",
       "           -4.0527e-02,  7.1106e-03]], requires_grad=True)),\n",
       " ('transformer.h.8.attn.attention.q_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0091, -0.0253, -0.1172,  ...,  0.0258,  0.0310, -0.0188],\n",
       "          [-0.0698, -0.0127, -0.0752,  ...,  0.0146,  0.0183,  0.0544],\n",
       "          [ 0.0874,  0.0684,  0.0143,  ..., -0.0618, -0.0388, -0.1040],\n",
       "          ...,\n",
       "          [ 0.0515, -0.0679, -0.0134,  ..., -0.0806, -0.0210, -0.0354],\n",
       "          [-0.0840, -0.0233,  0.0493,  ..., -0.0608,  0.0449,  0.0233],\n",
       "          [ 0.0703, -0.0156, -0.0019,  ..., -0.0128, -0.0298,  0.0364]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.8.attn.attention.out_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0601,  0.0713,  0.0135,  ..., -0.1025,  0.0708,  0.0840],\n",
       "          [ 0.0151,  0.0220, -0.0349,  ..., -0.0055, -0.0459, -0.0308],\n",
       "          [-0.0742,  0.0347,  0.1089,  ...,  0.0491,  0.0118, -0.0913],\n",
       "          ...,\n",
       "          [-0.0104, -0.0728,  0.0222,  ..., -0.0297, -0.0476, -0.0747],\n",
       "          [ 0.1406, -0.0962,  0.0161,  ..., -0.0325,  0.0435,  0.0002],\n",
       "          [-0.0009, -0.1680, -0.0138,  ...,  0.0854,  0.0430,  0.0166]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.8.attn.attention.out_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0527,  0.0110, -0.0083,  ..., -0.0408, -0.0272,  0.0305],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.8.ln_2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([1.4141, 1.4766, 1.5312,  ..., 1.5078, 1.4688, 1.4453],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.8.ln_2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0002,  0.0522, -0.0018,  ...,  0.0334,  0.0461,  0.0077],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.8.mlp.c_fc.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0248, -0.1260,  0.1055,  ...,  0.0996,  0.1123,  0.0757],\n",
       "          [ 0.0058, -0.0007, -0.0786,  ..., -0.0210, -0.1191, -0.0249],\n",
       "          [-0.0031, -0.0352,  0.0260,  ..., -0.0133,  0.0251,  0.0087],\n",
       "          ...,\n",
       "          [-0.1050, -0.0221,  0.0239,  ..., -0.1445, -0.0405,  0.0408],\n",
       "          [ 0.1602, -0.0400, -0.0011,  ...,  0.0432, -0.1338,  0.0156],\n",
       "          [-0.0115, -0.2432,  0.0850,  ...,  0.0222,  0.0469, -0.0049]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.8.mlp.c_fc.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0275, -0.0031,  0.0029,  ..., -0.0189, -0.0299, -0.0046],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.8.mlp.c_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0559,  0.0128, -0.0371,  ...,  0.0525, -0.0615,  0.0620],\n",
       "          [-0.0850, -0.0079,  0.0874,  ..., -0.0156, -0.0132,  0.0674],\n",
       "          [-0.1123,  0.0864,  0.0835,  ..., -0.0005,  0.0747, -0.0576],\n",
       "          ...,\n",
       "          [ 0.0420,  0.0791,  0.0162,  ...,  0.0598, -0.0261, -0.0245],\n",
       "          [ 0.0815,  0.0747, -0.0830,  ...,  0.0332,  0.0143, -0.0815],\n",
       "          [ 0.0182, -0.0337,  0.0265,  ...,  0.0099, -0.0306,  0.0120]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.8.mlp.c_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0265,  0.0052, -0.0156,  ..., -0.0593, -0.0420,  0.0209],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.9.ln_1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([0.6758, 0.7344, 0.7500,  ..., 0.7266, 0.7227, 0.7148],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.9.ln_1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0116, -0.0022,  0.0014,  ...,  0.0064,  0.0282, -0.0223],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.9.attn.attention.k_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1089, -0.0078,  0.0305,  ...,  0.1309, -0.0405, -0.0398],\n",
       "          [ 0.0248,  0.0498,  0.0703,  ...,  0.0757, -0.0115, -0.0273],\n",
       "          [ 0.0486,  0.1021, -0.0396,  ...,  0.0334,  0.0605, -0.0221],\n",
       "          ...,\n",
       "          [-0.0167, -0.1611,  0.0576,  ...,  0.0117,  0.0649, -0.0464],\n",
       "          [ 0.0615, -0.0304, -0.0869,  ...,  0.0454, -0.0118,  0.0344],\n",
       "          [-0.0276, -0.1182,  0.0376,  ...,  0.0786,  0.0603, -0.1069]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.9.attn.attention.v_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0530,  0.0461,  0.0425,  ...,  0.0366, -0.1074,  0.0269],\n",
       "          [ 0.0908, -0.0349, -0.0732,  ..., -0.0703, -0.0967, -0.0515],\n",
       "          [-0.0610,  0.0781, -0.0522,  ..., -0.0295,  0.1543,  0.0033],\n",
       "          ...,\n",
       "          [-0.0410, -0.0233, -0.0168,  ...,  0.1006, -0.0684,  0.1001],\n",
       "          [ 0.0136,  0.0913, -0.0090,  ...,  0.0008,  0.0039,  0.0649],\n",
       "          [-0.0236, -0.0058, -0.1064,  ...,  0.0403, -0.0057, -0.0830]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.9.attn.attention.q_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1318,  0.0082,  0.0447,  ...,  0.0388,  0.0854, -0.0640],\n",
       "          [-0.0713,  0.0320,  0.1025,  ..., -0.0176, -0.0444, -0.0236],\n",
       "          [-0.0139, -0.0156,  0.0371,  ...,  0.0055,  0.0237,  0.0033],\n",
       "          ...,\n",
       "          [-0.0918, -0.0593,  0.0320,  ...,  0.1016, -0.0255,  0.0630],\n",
       "          [-0.0598,  0.0640,  0.1064,  ...,  0.0059, -0.0425, -0.0154],\n",
       "          [-0.0615, -0.0200,  0.0227,  ..., -0.0889,  0.0089, -0.0342]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.9.attn.attention.out_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1064,  0.0090, -0.0432,  ...,  0.0122, -0.0403,  0.0513],\n",
       "          [ 0.0923, -0.0481, -0.0053,  ...,  0.0146, -0.0354,  0.0212],\n",
       "          [-0.0289, -0.0569,  0.0228,  ...,  0.0645, -0.0481,  0.0952],\n",
       "          ...,\n",
       "          [-0.0093, -0.0304, -0.1138,  ..., -0.0457,  0.0913, -0.0559],\n",
       "          [-0.0391,  0.0542, -0.0728,  ..., -0.1147, -0.0219,  0.0835],\n",
       "          [-0.0116, -0.0082,  0.0036,  ...,  0.0503, -0.0476,  0.0261]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.9.attn.attention.out_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0269,  0.0199, -0.0067,  ..., -0.0620, -0.0405,  0.0466],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.9.ln_2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([1.2266, 1.3359, 1.2969,  ..., 1.3516, 1.2656, 1.3203],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.9.ln_2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0262,  0.0306, -0.0193,  ..., -0.0250,  0.0227, -0.0225],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.9.mlp.c_fc.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 3.5645e-02,  3.3691e-02, -7.2327e-03,  ..., -3.8385e-05,\n",
       "            1.8921e-03,  1.2634e-02],\n",
       "          [ 4.9561e-02,  4.5654e-02,  7.9346e-03,  ...,  4.7363e-02,\n",
       "            1.0059e-01, -3.5400e-02],\n",
       "          [ 8.6670e-03, -1.0791e-01, -1.2598e-01,  ..., -2.1729e-02,\n",
       "            2.0630e-02,  8.3008e-02],\n",
       "          ...,\n",
       "          [-1.4404e-02,  2.7710e-02, -3.1128e-02,  ...,  2.8442e-02,\n",
       "           -8.4961e-02, -5.7129e-02],\n",
       "          [-1.3086e-01,  7.2266e-02,  1.8799e-02,  ..., -8.6914e-02,\n",
       "           -3.9551e-02, -1.2354e-01],\n",
       "          [ 3.6377e-02,  6.1646e-03,  4.3457e-02,  ...,  3.2227e-02,\n",
       "            9.2773e-03,  1.9141e-01]], requires_grad=True)),\n",
       " ('transformer.h.9.mlp.c_fc.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0518, -0.0400, -0.0302,  ...,  0.0075, -0.0168, -0.0203],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.9.mlp.c_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0361,  0.0474, -0.0664,  ..., -0.0427,  0.0684, -0.1123],\n",
       "          [-0.0330,  0.0547,  0.0474,  ...,  0.0530,  0.0762, -0.1260],\n",
       "          [-0.0099, -0.0593,  0.0957,  ...,  0.0212, -0.0618, -0.0136],\n",
       "          ...,\n",
       "          [-0.0192, -0.0742, -0.0864,  ..., -0.0242, -0.0291,  0.0126],\n",
       "          [-0.0255, -0.0237,  0.0048,  ...,  0.0640, -0.0309,  0.0588],\n",
       "          [ 0.0479, -0.0396, -0.0155,  ...,  0.0025, -0.0043,  0.0381]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.9.mlp.c_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0311,  0.0278,  0.0200,  ..., -0.0583, -0.0349,  0.0601],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.10.ln_1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([0.7852, 0.8633, 0.8711,  ..., 0.8633, 0.8281, 0.8633],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.10.ln_1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0344,  0.0186, -0.0146,  ...,  0.0271,  0.0133,  0.0134],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.10.attn.attention.k_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0194,  0.0055, -0.1455,  ..., -0.0674, -0.1108, -0.0024],\n",
       "          [-0.0732,  0.0043, -0.0459,  ..., -0.0197,  0.0396, -0.0142],\n",
       "          [ 0.0025, -0.0039,  0.0815,  ..., -0.0806,  0.0518, -0.0126],\n",
       "          ...,\n",
       "          [-0.0640,  0.0439,  0.0894,  ..., -0.0084, -0.0786,  0.0272],\n",
       "          [-0.0162,  0.0025, -0.0031,  ...,  0.0574, -0.0233, -0.0645],\n",
       "          [-0.0019, -0.0332,  0.0349,  ..., -0.0364, -0.0923,  0.0215]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.10.attn.attention.v_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0449, -0.0591, -0.0688,  ...,  0.2715,  0.0437,  0.1318],\n",
       "          [ 0.1016,  0.1138,  0.0452,  ..., -0.0698,  0.0248, -0.0069],\n",
       "          [-0.0137, -0.0767,  0.1631,  ..., -0.0986, -0.1113,  0.0014],\n",
       "          ...,\n",
       "          [-0.0469, -0.0361, -0.0231,  ...,  0.0108,  0.0610, -0.1924],\n",
       "          [ 0.0791,  0.0143, -0.0552,  ...,  0.0035, -0.0864, -0.1201],\n",
       "          [-0.0043,  0.0139,  0.0615,  ...,  0.1787, -0.0659,  0.1748]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.10.attn.attention.q_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0977, -0.0903,  0.0452,  ..., -0.0223, -0.0742,  0.0082],\n",
       "          [ 0.0002,  0.0293, -0.0291,  ...,  0.0229,  0.0503, -0.0112],\n",
       "          [ 0.0098,  0.0344, -0.0505,  ...,  0.0161, -0.0361,  0.0063],\n",
       "          ...,\n",
       "          [-0.0300,  0.0918,  0.0493,  ..., -0.0042, -0.0017,  0.0261],\n",
       "          [-0.0679, -0.0108,  0.0422,  ..., -0.0253, -0.0025, -0.0322],\n",
       "          [-0.0603,  0.0649, -0.0618,  ..., -0.0151, -0.0635,  0.0006]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.10.attn.attention.out_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0488, -0.0013,  0.0383,  ...,  0.1035, -0.0031,  0.0625],\n",
       "          [-0.0535, -0.0635,  0.0544,  ..., -0.0036, -0.0114,  0.0155],\n",
       "          [-0.0737, -0.0276, -0.0625,  ..., -0.0117, -0.0854, -0.0388],\n",
       "          ...,\n",
       "          [-0.0654, -0.1001,  0.0623,  ..., -0.0493,  0.0747, -0.1309],\n",
       "          [-0.1357,  0.1182, -0.0229,  ..., -0.1289, -0.0082, -0.0156],\n",
       "          [-0.1367, -0.1533, -0.0289,  ...,  0.0211,  0.0374, -0.0598]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.10.attn.attention.out_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0320,  0.0086,  0.0381,  ..., -0.0688, -0.0115,  0.0679],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.10.ln_2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([1.3203, 1.4141, 1.3906,  ..., 1.3984, 1.3828, 1.4453],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.10.ln_2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0586,  0.0781, -0.0148,  ..., -0.0112, -0.0110,  0.0503],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.10.mlp.c_fc.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0093,  0.0197, -0.0013,  ...,  0.0408, -0.0036,  0.0197],\n",
       "          [ 0.0028,  0.0267,  0.0204,  ...,  0.1611,  0.0977, -0.0171],\n",
       "          [-0.0300,  0.0869,  0.0118,  ..., -0.0466,  0.0106,  0.1270],\n",
       "          ...,\n",
       "          [-0.0972, -0.0708,  0.1050,  ..., -0.0026,  0.0840,  0.0204],\n",
       "          [ 0.1260, -0.1079, -0.1113,  ...,  0.0393, -0.0077, -0.1270],\n",
       "          [-0.0498,  0.0175,  0.0197,  ..., -0.1191,  0.0084,  0.0542]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.10.mlp.c_fc.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0291, -0.0354, -0.0094,  ..., -0.0175, -0.0405, -0.0415],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.10.mlp.c_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0016,  0.0148,  0.0153,  ...,  0.1367,  0.0508,  0.0271],\n",
       "          [-0.0430,  0.0520,  0.1260,  ...,  0.0297,  0.0996, -0.0245],\n",
       "          [-0.0398, -0.1157, -0.1172,  ..., -0.0923, -0.0947, -0.0623],\n",
       "          ...,\n",
       "          [-0.0598, -0.0928,  0.0056,  ..., -0.0679,  0.0623,  0.0581],\n",
       "          [-0.0505, -0.0613,  0.0042,  ..., -0.0017, -0.0835, -0.0305],\n",
       "          [ 0.0245,  0.0165,  0.0439,  ..., -0.0143, -0.0664,  0.1128]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.10.mlp.c_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0393, -0.0199,  0.0618,  ..., -0.0410, -0.0254,  0.0605],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.11.ln_1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([0.7578, 0.7773, 0.8047,  ..., 0.7891, 0.7344, 0.7852],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.11.ln_1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0203,  0.0216,  0.0284,  ..., -0.0090,  0.0159,  0.0132],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.11.attn.attention.k_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0026,  0.0481, -0.0277,  ..., -0.0203,  0.0488,  0.0284],\n",
       "          [-0.0179,  0.0125,  0.0325,  ...,  0.0723, -0.0942,  0.0518],\n",
       "          [ 0.0221, -0.0679,  0.1226,  ...,  0.0796, -0.0073, -0.0649],\n",
       "          ...,\n",
       "          [ 0.0466,  0.0486, -0.0564,  ...,  0.0306,  0.0060, -0.1006],\n",
       "          [ 0.0312, -0.0654, -0.0598,  ..., -0.0830, -0.0184,  0.0854],\n",
       "          [-0.0942,  0.0029,  0.0381,  ..., -0.0104,  0.0292,  0.0542]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.11.attn.attention.v_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1055,  0.0086, -0.1768,  ..., -0.0029, -0.0693, -0.1001],\n",
       "          [-0.0991, -0.0288, -0.0393,  ..., -0.1426, -0.0117, -0.0957],\n",
       "          [ 0.0220, -0.0040, -0.1050,  ...,  0.0181, -0.0781, -0.1455],\n",
       "          ...,\n",
       "          [ 0.0645, -0.1182,  0.0186,  ..., -0.1660,  0.1953, -0.0006],\n",
       "          [-0.0057, -0.0586, -0.0498,  ...,  0.0718,  0.1270,  0.1206],\n",
       "          [-0.1445, -0.2158, -0.0093,  ..., -0.0281, -0.0498,  0.1011]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.11.attn.attention.q_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0244, -0.0068,  0.0630,  ..., -0.0569,  0.1260, -0.0547],\n",
       "          [-0.0947, -0.0476,  0.0237,  ...,  0.0222,  0.0042,  0.0757],\n",
       "          [ 0.0058, -0.0211,  0.0214,  ..., -0.0066,  0.0393,  0.0029],\n",
       "          ...,\n",
       "          [ 0.0559,  0.0635, -0.0042,  ..., -0.0178,  0.0102, -0.0159],\n",
       "          [-0.0859,  0.0679, -0.0320,  ..., -0.0757,  0.1196, -0.0175],\n",
       "          [ 0.0400, -0.0151,  0.0527,  ..., -0.0776, -0.0184, -0.0033]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.11.attn.attention.out_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0864,  0.1250, -0.0289,  ...,  0.0178, -0.0255,  0.0222],\n",
       "          [ 0.0889, -0.0801,  0.0034,  ..., -0.1738, -0.0332,  0.0294],\n",
       "          [ 0.0942,  0.0825, -0.0184,  ..., -0.1621,  0.0679,  0.1201],\n",
       "          ...,\n",
       "          [-0.0518,  0.0471,  0.0017,  ...,  0.0508, -0.0129, -0.0552],\n",
       "          [ 0.1963, -0.0432,  0.0295,  ..., -0.0344, -0.0879,  0.0075],\n",
       "          [ 0.0125,  0.1299,  0.0996,  ...,  0.0747,  0.0791, -0.0500]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.11.attn.attention.out_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0491, -0.0236,  0.0476,  ..., -0.0310, -0.0172,  0.0674],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.11.ln_2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([1.2969, 1.3125, 1.3047,  ..., 1.3438, 1.3672, 1.3750],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.11.ln_2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0299,  0.0591,  0.0503,  ..., -0.0229, -0.0231,  0.0466],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.11.mlp.c_fc.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0864, -0.0073, -0.0002,  ..., -0.0098, -0.0469, -0.0016],\n",
       "          [-0.0199,  0.1001,  0.0537,  ...,  0.0003, -0.0371, -0.0942],\n",
       "          [-0.0095, -0.0079, -0.0129,  ...,  0.1895,  0.0145, -0.0737],\n",
       "          ...,\n",
       "          [ 0.0466,  0.0447, -0.0454,  ...,  0.0557,  0.0479,  0.0090],\n",
       "          [ 0.1328,  0.0728, -0.0815,  ...,  0.0012, -0.0115, -0.0618],\n",
       "          [-0.0488, -0.0444, -0.0786,  ..., -0.0308, -0.0752, -0.1748]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.11.mlp.c_fc.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0074, -0.0359, -0.0236,  ..., -0.0210, -0.0309, -0.0383],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.11.mlp.c_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0544, -0.0918, -0.0242,  ..., -0.0723, -0.0182, -0.0991],\n",
       "          [ 0.0177, -0.0972, -0.0052,  ...,  0.0569, -0.0069, -0.1338],\n",
       "          [-0.0284, -0.0417,  0.0742,  ..., -0.0121,  0.0581, -0.0021],\n",
       "          ...,\n",
       "          [ 0.0300, -0.0337, -0.0659,  ...,  0.0635,  0.0405,  0.0830],\n",
       "          [ 0.0898,  0.0383,  0.0728,  ...,  0.0359,  0.0820, -0.0781],\n",
       "          [-0.0342,  0.0991,  0.0248,  ..., -0.0500,  0.0006, -0.0315]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.11.mlp.c_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0432, -0.0247,  0.0391,  ..., -0.0120, -0.0261,  0.0640],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.12.ln_1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([0.7344, 0.7500, 0.7656,  ..., 0.7656, 0.7188, 0.7734],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.12.ln_1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0059,  0.0104, -0.0186,  ...,  0.0140,  0.0464,  0.0083],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.12.attn.attention.k_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0092,  0.0364, -0.0141,  ..., -0.0449, -0.0176,  0.0737],\n",
       "          [ 0.0087, -0.0153, -0.0205,  ..., -0.0645, -0.0125,  0.0403],\n",
       "          [ 0.0098,  0.0264,  0.0933,  ..., -0.0056,  0.0908,  0.0347],\n",
       "          ...,\n",
       "          [-0.0383,  0.0334, -0.0114,  ...,  0.0112,  0.0503,  0.0051],\n",
       "          [-0.1084, -0.0057,  0.0197,  ...,  0.0109,  0.0493,  0.0447],\n",
       "          [ 0.0280,  0.0033,  0.0155,  ...,  0.0141, -0.0055, -0.0654]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.12.attn.attention.v_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0518, -0.0579,  0.0737,  ..., -0.0198,  0.0262, -0.0593],\n",
       "          [ 0.0425, -0.0106,  0.0576,  ..., -0.1865,  0.0815, -0.0479],\n",
       "          [ 0.0183, -0.0737, -0.1094,  ..., -0.0791, -0.1631,  0.0002],\n",
       "          ...,\n",
       "          [ 0.0114, -0.1177,  0.1445,  ..., -0.0153, -0.0698, -0.0036],\n",
       "          [ 0.0249, -0.0718, -0.0359,  ...,  0.0889, -0.0139,  0.1553],\n",
       "          [-0.1592,  0.1309, -0.0050,  ..., -0.0288, -0.0908, -0.0141]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.12.attn.attention.q_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0874,  0.0165,  0.0132,  ..., -0.0864, -0.0825,  0.0674],\n",
       "          [ 0.0889,  0.0121,  0.0559,  ...,  0.0080,  0.0217,  0.0854],\n",
       "          [-0.0625, -0.1045, -0.0347,  ..., -0.0256, -0.0610, -0.1152],\n",
       "          ...,\n",
       "          [-0.0121, -0.0471,  0.1021,  ..., -0.0378, -0.0786, -0.0085],\n",
       "          [-0.0240,  0.0222, -0.0923,  ..., -0.0515,  0.1035, -0.0008],\n",
       "          [ 0.1309,  0.0679,  0.0449,  ..., -0.0522,  0.0032, -0.0525]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.12.attn.attention.out_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0483, -0.0118,  0.0214,  ...,  0.1299, -0.0977,  0.1436],\n",
       "          [-0.1011,  0.0825,  0.0019,  ...,  0.0625,  0.0771, -0.2041],\n",
       "          [ 0.1641,  0.0933, -0.1484,  ..., -0.2002,  0.0903, -0.0459],\n",
       "          ...,\n",
       "          [ 0.0981,  0.1260,  0.0304,  ...,  0.0835, -0.1562,  0.1138],\n",
       "          [ 0.0420, -0.0913,  0.0515,  ...,  0.0547,  0.0742,  0.0559],\n",
       "          [-0.0378, -0.0312,  0.0078,  ..., -0.0388, -0.0942,  0.0903]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.12.attn.attention.out_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0297, -0.0233,  0.0466,  ..., -0.0190, -0.0276,  0.0625],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.12.ln_2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([1.3750, 1.3906, 1.4141,  ..., 1.4219, 1.3359, 1.3984],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.12.ln_2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0287,  0.0300, -0.0157,  ...,  0.0302,  0.0247,  0.0142],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.12.mlp.c_fc.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 1.6016e-01, -6.8848e-02, -1.0986e-01,  ...,  5.9326e-02,\n",
       "            2.7344e-02, -1.2158e-01],\n",
       "          [-5.0964e-03, -6.5430e-02, -9.0332e-02,  ..., -1.6968e-02,\n",
       "            5.6152e-03, -5.3711e-03],\n",
       "          [-8.9355e-02,  1.0400e-01, -1.0254e-01,  ...,  1.4587e-02,\n",
       "            8.3984e-02, -1.5747e-02],\n",
       "          ...,\n",
       "          [-9.6680e-02, -9.2163e-03,  4.1504e-03,  ..., -7.1289e-02,\n",
       "           -3.3691e-02, -1.2112e-04],\n",
       "          [-9.6191e-02, -8.8379e-02,  3.9307e-02,  ...,  3.7842e-02,\n",
       "           -2.5635e-02, -3.5889e-02],\n",
       "          [ 2.1729e-02,  8.6426e-02, -1.3281e-01,  ...,  5.3223e-02,\n",
       "            9.4238e-02,  3.5858e-03]], requires_grad=True)),\n",
       " ('transformer.h.12.mlp.c_fc.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0369, -0.0154, -0.0369,  ..., -0.0277, -0.0317, -0.0106],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.12.mlp.c_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1094, -0.0483, -0.0053,  ...,  0.0938, -0.0327, -0.0332],\n",
       "          [-0.0830,  0.0669,  0.0908,  ...,  0.0022,  0.0933,  0.0515],\n",
       "          [ 0.0255,  0.1455,  0.0123,  ..., -0.0116, -0.0236,  0.0605],\n",
       "          ...,\n",
       "          [ 0.0364, -0.0140, -0.0090,  ...,  0.0894,  0.0381, -0.0469],\n",
       "          [ 0.0038,  0.0165,  0.0405,  ...,  0.0615,  0.0908,  0.0356],\n",
       "          [-0.0193,  0.0334, -0.0549,  ...,  0.0305, -0.0347, -0.0977]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.12.mlp.c_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0170, -0.0172,  0.0737,  ..., -0.0039, -0.0449,  0.0552],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.13.ln_1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([0.6680, 0.7227, 0.6992,  ..., 0.7227, 0.6523, 0.7344],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.13.ln_1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0087,  0.0151,  0.0342,  ..., -0.0030,  0.0337,  0.0186],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.13.attn.attention.k_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0559, -0.0298,  0.0277,  ..., -0.0845,  0.0354, -0.0615],\n",
       "          [ 0.1118, -0.0217, -0.0356,  ...,  0.0005, -0.0267,  0.0029],\n",
       "          [-0.0187, -0.0084,  0.0201,  ...,  0.0086,  0.0464, -0.0481],\n",
       "          ...,\n",
       "          [-0.0302, -0.0447,  0.0398,  ...,  0.0115, -0.0229,  0.0254],\n",
       "          [ 0.0332,  0.0752, -0.0569,  ..., -0.0601, -0.0386,  0.0869],\n",
       "          [-0.0537, -0.0742,  0.0222,  ..., -0.0374,  0.0248,  0.0222]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.13.attn.attention.v_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0027,  0.0664, -0.1035,  ...,  0.0201,  0.0256,  0.1055],\n",
       "          [-0.1060, -0.1631, -0.0236,  ..., -0.0544,  0.2148,  0.0071],\n",
       "          [-0.0613, -0.0052, -0.0386,  ..., -0.0767, -0.0359, -0.1533],\n",
       "          ...,\n",
       "          [-0.0132,  0.1689, -0.0007,  ..., -0.1406, -0.0503,  0.0864],\n",
       "          [ 0.1309, -0.0255, -0.0381,  ..., -0.0723,  0.1426, -0.0364],\n",
       "          [-0.1387,  0.1562, -0.0513,  ...,  0.0762, -0.0659, -0.0315]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.13.attn.attention.q_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0189,  0.0593,  0.0208,  ...,  0.0708,  0.0618, -0.0302],\n",
       "          [ 0.0070, -0.0688, -0.1216,  ..., -0.0272, -0.0291, -0.0312],\n",
       "          [-0.0105, -0.0996, -0.0347,  ..., -0.0197,  0.0308, -0.0400],\n",
       "          ...,\n",
       "          [ 0.0503, -0.1035,  0.0554,  ...,  0.0317,  0.0874,  0.0334],\n",
       "          [ 0.0227,  0.0320, -0.0159,  ..., -0.0933,  0.0193, -0.0186],\n",
       "          [-0.0957, -0.0669, -0.0250,  ...,  0.0635, -0.0293,  0.0189]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.13.attn.attention.out_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0291,  0.2285,  0.0332,  ...,  0.0132,  0.0293, -0.0344],\n",
       "          [-0.0796,  0.1670,  0.0403,  ...,  0.0393, -0.0009, -0.0613],\n",
       "          [ 0.1206, -0.0393,  0.0210,  ..., -0.0109, -0.0009, -0.0267],\n",
       "          ...,\n",
       "          [ 0.0391, -0.1230,  0.1152,  ..., -0.0276,  0.0005, -0.1240],\n",
       "          [ 0.0415, -0.1670,  0.0601,  ...,  0.1172,  0.0417, -0.0302],\n",
       "          [-0.1279, -0.0718,  0.1611,  ..., -0.0669, -0.0588, -0.0167]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.13.attn.attention.out_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0022, -0.0154,  0.0732,  ...,  0.0232, -0.0408,  0.0605],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.13.ln_2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([1.2578, 1.2969, 1.3125,  ..., 1.3203, 1.3203, 1.3125],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.13.ln_2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0187,  0.0322,  0.0732,  ...,  0.0072, -0.0152,  0.0566],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.13.mlp.c_fc.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0610,  0.0703, -0.1104,  ...,  0.0991, -0.0503, -0.0659],\n",
       "          [-0.0229,  0.1045, -0.0251,  ...,  0.1187, -0.0297, -0.0083],\n",
       "          [-0.0879, -0.0275, -0.1035,  ..., -0.0039, -0.0344, -0.0466],\n",
       "          ...,\n",
       "          [ 0.0381, -0.0317,  0.0339,  ...,  0.1279,  0.0214, -0.0291],\n",
       "          [ 0.0099, -0.0535, -0.2129,  ...,  0.0292,  0.2070,  0.0513],\n",
       "          [-0.0398, -0.0310, -0.0242,  ...,  0.0110, -0.0209, -0.0791]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.13.mlp.c_fc.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0260, -0.0078, -0.0476,  ..., -0.0308, -0.0073, -0.0359],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.13.mlp.c_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0762, -0.0564,  0.0564,  ...,  0.0142, -0.1572,  0.0026],\n",
       "          [ 0.0679, -0.0649,  0.0479,  ..., -0.0571,  0.1523, -0.0474],\n",
       "          [ 0.0610, -0.0161, -0.0123,  ...,  0.0747,  0.1416,  0.0815],\n",
       "          ...,\n",
       "          [ 0.0439, -0.0063,  0.0640,  ..., -0.0283, -0.1123, -0.0835],\n",
       "          [-0.0147, -0.0226,  0.0255,  ...,  0.0082, -0.0625,  0.0344],\n",
       "          [ 0.0542,  0.0654, -0.0025,  ...,  0.0018, -0.0461,  0.2695]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.13.mlp.c_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0014, -0.0189,  0.0449,  ...,  0.0210, -0.0547,  0.0378],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.14.ln_1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([0.6875, 0.7188, 0.7227,  ..., 0.7148, 0.6836, 0.7109],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.14.ln_1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 6.8054e-03,  1.1414e-02,  2.2054e-05,  ..., -3.5553e-03,\n",
       "           3.1006e-02,  4.1016e-02], requires_grad=True)),\n",
       " ('transformer.h.14.attn.attention.k_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0869, -0.0317,  0.0337,  ...,  0.0757, -0.0432, -0.0437],\n",
       "          [-0.0024, -0.0260, -0.0620,  ..., -0.0500,  0.0557, -0.0240],\n",
       "          [ 0.0388, -0.0933, -0.0106,  ...,  0.0288, -0.1177,  0.0005],\n",
       "          ...,\n",
       "          [-0.0684, -0.0320,  0.0603,  ..., -0.1138,  0.0535,  0.0215],\n",
       "          [-0.0339,  0.0212, -0.0325,  ...,  0.0082, -0.0190,  0.0003],\n",
       "          [ 0.0212, -0.0084,  0.0277,  ...,  0.0004, -0.0410,  0.0413]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.14.attn.attention.v_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0815,  0.0048,  0.0791,  ..., -0.0952,  0.1235, -0.0029],\n",
       "          [-0.0713, -0.0554,  0.0269,  ...,  0.0396, -0.0918, -0.0271],\n",
       "          [-0.1289, -0.1123, -0.0544,  ..., -0.0330, -0.0564, -0.1523],\n",
       "          ...,\n",
       "          [ 0.0723, -0.0447,  0.0153,  ..., -0.0488,  0.0109, -0.0003],\n",
       "          [-0.0510, -0.0014,  0.0067,  ..., -0.0620, -0.1455, -0.2119],\n",
       "          [-0.0693, -0.0884,  0.0299,  ..., -0.0110,  0.0101, -0.0967]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.14.attn.attention.q_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0393,  0.0095, -0.0618,  ...,  0.0190, -0.0212, -0.0493],\n",
       "          [ 0.0051, -0.0464, -0.0457,  ...,  0.0184,  0.1108, -0.0486],\n",
       "          [ 0.0160,  0.0148, -0.0981,  ..., -0.0496, -0.0806,  0.0549],\n",
       "          ...,\n",
       "          [ 0.0312,  0.0425, -0.0928,  ...,  0.0229, -0.0014,  0.0194],\n",
       "          [ 0.0159,  0.1309,  0.0147,  ..., -0.0537,  0.0874, -0.0698],\n",
       "          [-0.0398, -0.0491, -0.1553,  ..., -0.0723, -0.0278, -0.0723]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.14.attn.attention.out_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0654,  0.1133,  0.0378,  ...,  0.0103,  0.0703, -0.0967],\n",
       "          [ 0.0215,  0.0008,  0.0669,  ...,  0.0752,  0.0273,  0.0221],\n",
       "          [-0.0189,  0.0258,  0.0150,  ..., -0.0430, -0.1260, -0.0036],\n",
       "          ...,\n",
       "          [ 0.0630, -0.1108,  0.0203,  ..., -0.0143, -0.0515,  0.0479],\n",
       "          [-0.0947,  0.1123,  0.0015,  ..., -0.0957,  0.0708,  0.0535],\n",
       "          [-0.0127,  0.0311,  0.1787,  ..., -0.1226,  0.0835, -0.0645]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.14.attn.attention.out_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0026, -0.0255,  0.0432,  ...,  0.0320, -0.0571,  0.0248],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.14.ln_2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([1.3281, 1.3203, 1.3672,  ..., 1.3828, 1.3750, 1.3359],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.14.ln_2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0033,  0.0265,  0.0149,  ...,  0.0035, -0.0347,  0.0889],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.14.mlp.c_fc.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0403, -0.0221, -0.0095,  ..., -0.0291, -0.0679,  0.0195],\n",
       "          [ 0.1206,  0.0596, -0.0815,  ...,  0.0508,  0.1348,  0.0146],\n",
       "          [ 0.1064, -0.0535, -0.0474,  ...,  0.0439,  0.0583, -0.0049],\n",
       "          ...,\n",
       "          [-0.0391,  0.0287, -0.0018,  ..., -0.1133,  0.1279, -0.0515],\n",
       "          [ 0.0043,  0.0253,  0.1406,  ...,  0.0591,  0.0623, -0.0270],\n",
       "          [-0.0354,  0.1045,  0.0371,  ..., -0.0791, -0.0291, -0.0337]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.14.mlp.c_fc.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0615, -0.0238, -0.0337,  ..., -0.0481, -0.0153, -0.0160],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.14.mlp.c_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0508, -0.0210, -0.0302,  ...,  0.0544,  0.0376,  0.0859],\n",
       "          [ 0.0601, -0.0596, -0.0320,  ...,  0.0128, -0.0583, -0.0957],\n",
       "          [ 0.0669,  0.1069, -0.1104,  ...,  0.0640, -0.0903, -0.0898],\n",
       "          ...,\n",
       "          [ 0.1060, -0.0544, -0.0244,  ..., -0.0204, -0.0515,  0.0669],\n",
       "          [ 0.1152, -0.0275,  0.0262,  ..., -0.0153, -0.1523, -0.0223],\n",
       "          [-0.0928,  0.0226,  0.0261,  ..., -0.0771, -0.1035, -0.0273]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.14.mlp.c_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0233, -0.0278,  0.0618,  ...,  0.0505, -0.0654,  0.0030],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.15.ln_1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([0.6367, 0.6484, 0.6680,  ..., 0.6367, 0.6055, 0.6719],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.15.ln_1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0077,  0.0143,  0.0208,  ..., -0.0120,  0.0283,  0.0177],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.15.attn.attention.k_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0515,  0.1118, -0.0270,  ..., -0.0806,  0.1338,  0.0053],\n",
       "          [-0.0244, -0.0510,  0.0275,  ..., -0.0374, -0.0255,  0.0835],\n",
       "          [-0.0320,  0.0376,  0.0391,  ...,  0.0337, -0.0011, -0.0311],\n",
       "          ...,\n",
       "          [-0.0044,  0.0781, -0.0199,  ...,  0.0898, -0.0532, -0.1089],\n",
       "          [-0.0557,  0.0251,  0.0214,  ..., -0.0270, -0.0087,  0.0625],\n",
       "          [ 0.0014, -0.0356,  0.0669,  ..., -0.0050, -0.0190, -0.0115]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.15.attn.attention.v_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1357, -0.1543, -0.1699,  ...,  0.0019, -0.0118,  0.0408],\n",
       "          [-0.0610,  0.0693, -0.1089,  ...,  0.0134, -0.0938,  0.1846],\n",
       "          [-0.1187,  0.0781,  0.0100,  ...,  0.0168,  0.0347,  0.0894],\n",
       "          ...,\n",
       "          [-0.0065, -0.1021, -0.1406,  ...,  0.0723, -0.0262, -0.0144],\n",
       "          [-0.0679,  0.1523,  0.0123,  ...,  0.0435,  0.2158, -0.0811],\n",
       "          [ 0.0457,  0.0527, -0.0786,  ..., -0.0811,  0.0109, -0.0125]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.15.attn.attention.q_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0356, -0.0327,  0.0403,  ...,  0.0172,  0.0337, -0.0625],\n",
       "          [ 0.0879,  0.1318, -0.0248,  ...,  0.0396,  0.1016,  0.0060],\n",
       "          [-0.0267,  0.0444,  0.0508,  ...,  0.0811,  0.0091, -0.0238],\n",
       "          ...,\n",
       "          [ 0.0645,  0.0282, -0.0454,  ..., -0.0620, -0.0898, -0.0187],\n",
       "          [-0.0435,  0.0109,  0.1016,  ..., -0.0330,  0.0522, -0.0449],\n",
       "          [-0.1680, -0.0079, -0.1084,  ...,  0.0688,  0.0203, -0.0381]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.15.attn.attention.out_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0693,  0.1494,  0.1367,  ..., -0.0227,  0.0884, -0.0325],\n",
       "          [ 0.1113,  0.1230,  0.0036,  ...,  0.0223, -0.0864,  0.0564],\n",
       "          [ 0.1768, -0.0119,  0.0112,  ..., -0.0386,  0.0028, -0.0806],\n",
       "          ...,\n",
       "          [-0.0264,  0.0403, -0.0476,  ..., -0.0659,  0.0165,  0.0742],\n",
       "          [ 0.0236,  0.1099, -0.0427,  ...,  0.1050, -0.0752, -0.0469],\n",
       "          [-0.0147,  0.0030,  0.0299,  ...,  0.0503, -0.0223,  0.0190]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.15.attn.attention.out_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0388, -0.0219,  0.0452,  ...,  0.0630, -0.0645,  0.0117],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.15.ln_2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([1.2734, 1.3281, 1.2891,  ..., 1.3984, 1.3125, 1.3047],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.15.ln_2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0132,  0.0366,  0.0737,  ...,  0.0277, -0.0192,  0.0461],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.15.mlp.c_fc.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0330, -0.0574, -0.0549,  ...,  0.0006,  0.0825,  0.1729],\n",
       "          [-0.1475,  0.0312,  0.0481,  ..., -0.1182, -0.0547, -0.0161],\n",
       "          [ 0.0654, -0.0376,  0.0874,  ..., -0.1416, -0.0116, -0.0043],\n",
       "          ...,\n",
       "          [-0.0474,  0.1445,  0.0148,  ..., -0.1040,  0.0913, -0.0317],\n",
       "          [-0.0476,  0.0054,  0.0796,  ..., -0.0767, -0.0306, -0.0260],\n",
       "          [ 0.0408, -0.1143, -0.0889,  ...,  0.0498, -0.0576, -0.1221]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.15.mlp.c_fc.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0094, -0.0111, -0.0417,  ..., -0.0498, -0.0247,  0.0090],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.15.mlp.c_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0352,  0.0198, -0.0366,  ..., -0.0369, -0.0243,  0.0425],\n",
       "          [-0.0723,  0.0087, -0.0581,  ...,  0.0144,  0.1123,  0.0332],\n",
       "          [ 0.0033,  0.0452, -0.1738,  ..., -0.0552, -0.1113,  0.1270],\n",
       "          ...,\n",
       "          [ 0.0598, -0.0903, -0.0337,  ..., -0.0869,  0.0297,  0.0228],\n",
       "          [-0.0957,  0.0491, -0.0118,  ..., -0.0469,  0.0461, -0.0918],\n",
       "          [ 0.0723,  0.0393, -0.0981,  ..., -0.0859, -0.1167,  0.0092]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.15.mlp.c_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0439, -0.0168,  0.0342,  ...,  0.0447, -0.0669, -0.0036],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.16.ln_1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([0.6562, 0.6445, 0.6680,  ..., 0.6445, 0.6172, 0.6484],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.16.ln_1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0106,  0.0028,  0.0069,  ..., -0.0012,  0.0415,  0.0388],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.16.attn.attention.k_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1309,  0.0957,  0.0625,  ..., -0.0149,  0.0608,  0.0879],\n",
       "          [ 0.0228,  0.0369, -0.0552,  ...,  0.0530,  0.1064,  0.0040],\n",
       "          [ 0.0182, -0.0530,  0.0293,  ..., -0.0107,  0.0219, -0.0164],\n",
       "          ...,\n",
       "          [-0.0011, -0.0074,  0.0146,  ...,  0.0291, -0.0247, -0.0143],\n",
       "          [ 0.0199, -0.0403,  0.0184,  ..., -0.0732,  0.0081, -0.0172],\n",
       "          [-0.0090,  0.0591,  0.0038,  ...,  0.0305, -0.0540, -0.0349]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.16.attn.attention.v_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1650,  0.1035,  0.0664,  ...,  0.0938, -0.0420, -0.0249],\n",
       "          [ 0.1807, -0.1006, -0.0986,  ...,  0.0483, -0.0284, -0.0186],\n",
       "          [ 0.0293,  0.2129,  0.0078,  ...,  0.0620,  0.0182,  0.2598],\n",
       "          ...,\n",
       "          [ 0.0894,  0.0623,  0.1396,  ..., -0.0466,  0.1001, -0.0012],\n",
       "          [-0.1562,  0.0094, -0.1113,  ..., -0.0520, -0.0396, -0.0430],\n",
       "          [-0.1030, -0.1758,  0.1455,  ...,  0.0140,  0.1377,  0.1357]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.16.attn.attention.q_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0147, -0.0708, -0.0742,  ..., -0.0513,  0.0457,  0.0376],\n",
       "          [-0.0342, -0.0031,  0.0013,  ...,  0.0469,  0.0249, -0.0018],\n",
       "          [-0.0898, -0.0972, -0.0457,  ..., -0.0718,  0.0422, -0.0085],\n",
       "          ...,\n",
       "          [-0.0564, -0.0204,  0.0610,  ..., -0.0317, -0.0162, -0.0400],\n",
       "          [ 0.0162, -0.0286,  0.0090,  ..., -0.0737, -0.0649, -0.0376],\n",
       "          [-0.0618, -0.0571, -0.0297,  ..., -0.0233,  0.0986,  0.0249]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.16.attn.attention.out_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0918,  0.2754, -0.0454,  ...,  0.1206, -0.0771,  0.0508],\n",
       "          [ 0.0483, -0.0259, -0.1240,  ...,  0.0287,  0.1011,  0.0447],\n",
       "          [ 0.0510, -0.1074, -0.1270,  ...,  0.0233, -0.0815,  0.1533],\n",
       "          ...,\n",
       "          [-0.0938,  0.0040,  0.0835,  ...,  0.0967, -0.2119,  0.0493],\n",
       "          [-0.0083,  0.0024, -0.0342,  ...,  0.0669,  0.0588, -0.0093],\n",
       "          [ 0.1191,  0.1406, -0.0061,  ...,  0.2598, -0.0957, -0.1177]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.16.attn.attention.out_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0532, -0.0090,  0.0260,  ...,  0.0625, -0.0693, -0.0172],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.16.ln_2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([1.2969, 1.3281, 1.3594,  ..., 1.3984, 1.3281, 1.3125],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.16.ln_2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0029,  0.0044,  0.0537,  ...,  0.0302, -0.0098,  0.0625],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.16.mlp.c_fc.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0193,  0.0146, -0.0308,  ...,  0.0099, -0.0640, -0.0435],\n",
       "          [-0.0201, -0.1201,  0.0479,  ...,  0.0242,  0.0762, -0.1055],\n",
       "          [-0.0320,  0.0162, -0.1172,  ...,  0.0008, -0.0096, -0.0850],\n",
       "          ...,\n",
       "          [-0.0152,  0.0120,  0.0752,  ..., -0.0192,  0.0552, -0.0854],\n",
       "          [-0.1143,  0.0415,  0.1787,  ..., -0.0859,  0.0674, -0.0113],\n",
       "          [-0.0464, -0.1309, -0.1396,  ...,  0.0232,  0.0337,  0.0320]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.16.mlp.c_fc.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0031, -0.0210, -0.0469,  ..., -0.0527, -0.0165, -0.0923],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.16.mlp.c_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0403, -0.0393, -0.0591,  ...,  0.0229,  0.0018,  0.0159],\n",
       "          [ 0.0442, -0.0303, -0.0172,  ..., -0.1060,  0.0767, -0.0718],\n",
       "          [ 0.0084, -0.0275,  0.0610,  ..., -0.0918, -0.0135,  0.0410],\n",
       "          ...,\n",
       "          [-0.0947,  0.1006, -0.0762,  ...,  0.0303,  0.0337,  0.0084],\n",
       "          [ 0.0610,  0.0299, -0.0337,  ...,  0.1240,  0.0825, -0.0332],\n",
       "          [ 0.1079,  0.0625,  0.0320,  ...,  0.0674,  0.1660, -0.1367]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.16.mlp.c_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0659, -0.0070,  0.0175,  ...,  0.0645, -0.0615, -0.0334],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.17.ln_1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([0.5820, 0.5820, 0.6094,  ..., 0.5898, 0.5508, 0.6094],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.17.ln_1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0143, -0.0045,  0.0225,  ..., -0.0120,  0.0444,  0.0177],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.17.attn.attention.k_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0552, -0.0117,  0.0537,  ..., -0.0132, -0.1094,  0.0417],\n",
       "          [-0.0201, -0.0640,  0.0625,  ..., -0.0085, -0.0312, -0.0718],\n",
       "          [ 0.0088, -0.0040, -0.0510,  ..., -0.0732,  0.0481,  0.1260],\n",
       "          ...,\n",
       "          [-0.0312, -0.0004,  0.0294,  ..., -0.0552, -0.0048, -0.0018],\n",
       "          [-0.0525, -0.0225,  0.0461,  ..., -0.0083, -0.0334, -0.0101],\n",
       "          [ 0.0320,  0.0222,  0.0137,  ..., -0.0077,  0.1235, -0.0151]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.17.attn.attention.v_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0625, -0.0302,  0.0713,  ..., -0.0874, -0.0623,  0.0698],\n",
       "          [ 0.0505, -0.1016,  0.1133,  ..., -0.0972, -0.0018,  0.0457],\n",
       "          [ 0.0160,  0.0170,  0.1348,  ..., -0.1260,  0.1211, -0.0195],\n",
       "          ...,\n",
       "          [-0.0796,  0.0050, -0.1514,  ...,  0.1074,  0.0967, -0.0938],\n",
       "          [ 0.0786,  0.2217,  0.0854,  ...,  0.1143, -0.0398, -0.0894],\n",
       "          [ 0.0767,  0.0327,  0.0491,  ...,  0.0776, -0.0354, -0.0586]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.17.attn.attention.q_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0376, -0.0077, -0.0552,  ...,  0.0143, -0.0972,  0.0840],\n",
       "          [ 0.0708,  0.0869, -0.0359,  ...,  0.0269, -0.0234,  0.0113],\n",
       "          [ 0.0361,  0.0244, -0.0703,  ...,  0.0369, -0.1260, -0.0251],\n",
       "          ...,\n",
       "          [-0.0596, -0.0076, -0.0309,  ..., -0.0352, -0.0581, -0.0874],\n",
       "          [-0.0913, -0.0767,  0.0427,  ..., -0.0708, -0.0142,  0.0282],\n",
       "          [-0.0155, -0.0442,  0.0046,  ...,  0.0189,  0.0118, -0.0396]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.17.attn.attention.out_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0339, -0.0110,  0.0757,  ..., -0.0176,  0.1187, -0.2490],\n",
       "          [ 0.0854,  0.0420, -0.0608,  ..., -0.0664, -0.0435,  0.0806],\n",
       "          [-0.0025, -0.0840, -0.0294,  ...,  0.1279, -0.1157,  0.0625],\n",
       "          ...,\n",
       "          [-0.0065,  0.1289, -0.0620,  ..., -0.0234, -0.0028,  0.0498],\n",
       "          [-0.1992, -0.0347,  0.0178,  ..., -0.1631, -0.1621, -0.0461],\n",
       "          [-0.0500,  0.0762,  0.0374,  ...,  0.1089, -0.0559,  0.0796]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.17.attn.attention.out_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0679,  0.0120,  0.0045,  ...,  0.0869, -0.0605, -0.0308],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.17.ln_2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([1.2344, 1.2422, 1.2656,  ..., 1.2891, 1.2422, 1.2578],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.17.ln_2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0.0214, 0.0092, 0.0337,  ..., 0.0194, 0.0097, 0.0134],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.17.mlp.c_fc.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 5.0964e-03, -2.2363e-01, -1.3574e-01,  ..., -1.0156e-01,\n",
       "           -2.3193e-02, -1.4465e-02],\n",
       "          [ 3.5400e-02,  1.5332e-01, -4.1260e-02,  ..., -1.1169e-02,\n",
       "            2.7466e-02,  1.0986e-01],\n",
       "          [-4.1260e-02,  3.1738e-02, -4.3457e-02,  ...,  4.6387e-02,\n",
       "            2.9541e-02, -6.2500e-02],\n",
       "          ...,\n",
       "          [-6.3477e-02,  9.0820e-02,  1.3379e-01,  ..., -6.8848e-02,\n",
       "           -1.8799e-02, -7.9956e-03],\n",
       "          [-8.2397e-03,  6.1279e-02, -1.0559e-02,  ..., -8.0078e-02,\n",
       "           -8.1055e-02,  8.8379e-02],\n",
       "          [ 8.7280e-03,  7.0801e-02,  2.0447e-03,  ...,  1.1816e-01,\n",
       "           -3.4332e-05,  1.6113e-01]], requires_grad=True)),\n",
       " ('transformer.h.17.mlp.c_fc.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0393, -0.0297, -0.0361,  ..., -0.0413, -0.0649, -0.0150],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.17.mlp.c_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0825, -0.0576, -0.0386,  ...,  0.0033,  0.0260,  0.0162],\n",
       "          [ 0.1172, -0.0928,  0.0044,  ...,  0.0138, -0.0625, -0.0284],\n",
       "          [-0.0226, -0.0718, -0.0583,  ..., -0.0442, -0.0391,  0.0309],\n",
       "          ...,\n",
       "          [-0.1025, -0.1396,  0.0049,  ...,  0.0294,  0.0393, -0.1113],\n",
       "          [ 0.0723, -0.0776, -0.0369,  ...,  0.0483, -0.0825,  0.0698],\n",
       "          [ 0.0165, -0.0183,  0.0698,  ..., -0.0796,  0.0962, -0.0850]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.17.mlp.c_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0688,  0.0168, -0.0011,  ...,  0.0703, -0.0654, -0.0259],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.18.ln_1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([0.5742, 0.5742, 0.5977,  ..., 0.5820, 0.5742, 0.5742],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.18.ln_1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0.0111, 0.0126, 0.0079,  ..., 0.0121, 0.0398, 0.0266],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.18.attn.attention.k_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0136,  0.0510, -0.0352,  ..., -0.1445,  0.0684,  0.0025],\n",
       "          [-0.0442, -0.0391,  0.0303,  ..., -0.0282,  0.1133,  0.0243],\n",
       "          [-0.0469, -0.0454,  0.0161,  ..., -0.0806,  0.0148,  0.0206],\n",
       "          ...,\n",
       "          [ 0.0015, -0.0781, -0.0073,  ..., -0.0189, -0.0713, -0.0354],\n",
       "          [ 0.0077,  0.0277,  0.0016,  ...,  0.0205, -0.0322,  0.0972],\n",
       "          [ 0.0013, -0.1816,  0.0391,  ...,  0.0109, -0.0571,  0.0172]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.18.attn.attention.v_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1641,  0.0688, -0.0334,  ..., -0.0728,  0.0713,  0.0564],\n",
       "          [-0.0165, -0.0013,  0.0212,  ...,  0.1318, -0.0106, -0.0280],\n",
       "          [-0.0269,  0.1221, -0.0013,  ...,  0.0488, -0.1108,  0.0525],\n",
       "          ...,\n",
       "          [ 0.0874,  0.0273, -0.0129,  ..., -0.0425, -0.0532,  0.0164],\n",
       "          [-0.0074, -0.0422, -0.1172,  ..., -0.0047, -0.1436, -0.0625],\n",
       "          [ 0.0703, -0.0442, -0.0535,  ...,  0.0417,  0.0165,  0.0552]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.18.attn.attention.q_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0623, -0.0080, -0.1099,  ..., -0.0071,  0.0322,  0.0192],\n",
       "          [-0.0048, -0.0581,  0.0437,  ..., -0.0645,  0.0752,  0.0432],\n",
       "          [-0.0776, -0.0189,  0.0128,  ...,  0.0013, -0.0299,  0.0588],\n",
       "          ...,\n",
       "          [-0.0850,  0.0144,  0.0483,  ..., -0.0776, -0.0442, -0.0306],\n",
       "          [-0.0146, -0.0581,  0.0654,  ...,  0.1069, -0.0015, -0.0070],\n",
       "          [-0.0354,  0.0078, -0.0042,  ..., -0.0170,  0.0605,  0.0430]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.18.attn.attention.out_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1758, -0.1328, -0.0771,  ..., -0.0688, -0.0713,  0.0791],\n",
       "          [ 0.0674, -0.2217, -0.0801,  ...,  0.0247,  0.0210, -0.0879],\n",
       "          [ 0.0579,  0.0981, -0.0718,  ..., -0.0075, -0.1157,  0.1011],\n",
       "          ...,\n",
       "          [ 0.0569, -0.1133, -0.0117,  ..., -0.0015,  0.0840,  0.1270],\n",
       "          [ 0.0649, -0.0525,  0.0903,  ...,  0.0222, -0.0320,  0.1221],\n",
       "          [-0.1025, -0.0188, -0.0291,  ...,  0.0457, -0.0002, -0.1011]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.18.attn.attention.out_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0674,  0.0192, -0.0030,  ...,  0.0728, -0.0596, -0.0234],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.18.ln_2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([1.2188, 1.2344, 1.2578,  ..., 1.2891, 1.2188, 1.2500],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.18.ln_2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0.0374, 0.0302, 0.0046,  ..., 0.0542, 0.0084, 0.0117],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.18.mlp.c_fc.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0133, -0.0233, -0.0019,  ..., -0.0461,  0.1099, -0.0342],\n",
       "          [ 0.0161,  0.0566,  0.0129,  ...,  0.0276, -0.0310, -0.0544],\n",
       "          [ 0.1089,  0.0388,  0.0422,  ...,  0.0493,  0.0203, -0.0106],\n",
       "          ...,\n",
       "          [-0.0332, -0.0679,  0.0305,  ..., -0.0311,  0.0732,  0.0452],\n",
       "          [-0.1025,  0.0094, -0.0172,  ...,  0.0175,  0.0776,  0.0537],\n",
       "          [ 0.0586, -0.0130, -0.1074,  ..., -0.0583,  0.1230,  0.0283]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.18.mlp.c_fc.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0354, -0.0055, -0.0184,  ..., -0.0400, -0.0244, -0.0698],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.18.mlp.c_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0364, -0.1240, -0.0349,  ..., -0.0544, -0.0737, -0.0383],\n",
       "          [ 0.0256,  0.1504, -0.0923,  ..., -0.1279,  0.0060,  0.0952],\n",
       "          [ 0.0674, -0.0332,  0.0461,  ..., -0.0192,  0.1226,  0.0559],\n",
       "          ...,\n",
       "          [ 0.0947,  0.1118,  0.1426,  ...,  0.0047,  0.0042,  0.0054],\n",
       "          [ 0.0092,  0.0284,  0.0752,  ..., -0.0542,  0.0732,  0.0952],\n",
       "          [-0.0874, -0.0192,  0.0243,  ..., -0.0294, -0.0530, -0.0801]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.18.mlp.c_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0664,  0.0205, -0.0020,  ...,  0.0593, -0.0437, -0.0087],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.19.ln_1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([0.4961, 0.5508, 0.5469,  ..., 0.5039, 0.5156, 0.5547],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.19.ln_1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0.0157, 0.0034, 0.0129,  ..., 0.0145, 0.0425, 0.0170],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.19.attn.attention.k_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0059,  0.0006, -0.0361,  ...,  0.0166,  0.0400,  0.0156],\n",
       "          [ 0.0184,  0.0262, -0.0549,  ..., -0.0581, -0.0791,  0.0454],\n",
       "          [ 0.0737, -0.0102,  0.0659,  ...,  0.0408,  0.0393,  0.0400],\n",
       "          ...,\n",
       "          [-0.0732,  0.0515, -0.0275,  ...,  0.0284,  0.0127,  0.0265],\n",
       "          [-0.0908,  0.0342, -0.0306,  ..., -0.0033, -0.0132, -0.0217],\n",
       "          [ 0.0608, -0.0352,  0.0126,  ..., -0.0171,  0.0869, -0.0275]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.19.attn.attention.v_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0168,  0.0815,  0.0024,  ..., -0.0767,  0.0091, -0.0256],\n",
       "          [ 0.0203,  0.0732,  0.0559,  ...,  0.0684, -0.0109,  0.0596],\n",
       "          [-0.0410,  0.1084, -0.1299,  ..., -0.0461,  0.0400, -0.0498],\n",
       "          ...,\n",
       "          [ 0.0574,  0.0151, -0.0564,  ..., -0.0542,  0.0116, -0.0184],\n",
       "          [ 0.0317,  0.0238,  0.0204,  ..., -0.0649,  0.0337,  0.0212],\n",
       "          [ 0.0918,  0.1206, -0.0200,  ...,  0.0442,  0.0645,  0.0347]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.19.attn.attention.q_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0132,  0.0261, -0.0187,  ..., -0.0645,  0.0027,  0.0366],\n",
       "          [ 0.0322, -0.0188,  0.0090,  ...,  0.0068,  0.0104,  0.0339],\n",
       "          [ 0.0089,  0.0055,  0.0036,  ..., -0.0374,  0.0172,  0.0815],\n",
       "          ...,\n",
       "          [-0.1196, -0.0625, -0.0510,  ..., -0.0684,  0.0211, -0.0320],\n",
       "          [-0.0070,  0.0361, -0.0374,  ...,  0.0154,  0.0322,  0.0143],\n",
       "          [-0.0435,  0.0079,  0.0138,  ..., -0.0093, -0.0007, -0.0131]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.19.attn.attention.out_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0123,  0.0417, -0.0549,  ..., -0.0253, -0.0588, -0.0119],\n",
       "          [-0.0610,  0.1299, -0.0898,  ..., -0.0566, -0.0153,  0.0019],\n",
       "          [ 0.0879, -0.0933, -0.0398,  ..., -0.0752, -0.1436, -0.0674],\n",
       "          ...,\n",
       "          [ 0.0437, -0.0547, -0.0796,  ..., -0.0479,  0.0547, -0.0152],\n",
       "          [-0.0540, -0.0204, -0.0767,  ..., -0.0518, -0.0020, -0.0957],\n",
       "          [ 0.0505,  0.1118, -0.0283,  ..., -0.0579, -0.0015, -0.0145]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.19.attn.attention.out_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0645,  0.0236, -0.0043,  ...,  0.0503, -0.0479, -0.0047],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.19.ln_2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([1.2109, 1.1875, 1.2188,  ..., 1.3281, 1.1562, 1.2500],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.19.ln_2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0.0449, 0.0140, 0.0245,  ..., 0.1104, 0.0219, 0.0203],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.19.mlp.c_fc.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0388,  0.1025, -0.0073,  ..., -0.0288, -0.0693,  0.0334],\n",
       "          [ 0.0134,  0.0752,  0.0586,  ..., -0.0889,  0.0095, -0.0046],\n",
       "          [ 0.0664,  0.0059,  0.0259,  ..., -0.0603, -0.0986,  0.0771],\n",
       "          ...,\n",
       "          [-0.1206, -0.0854,  0.0297,  ...,  0.0152, -0.0391, -0.0583],\n",
       "          [-0.0806,  0.1270,  0.0469,  ..., -0.0530,  0.0209, -0.0620],\n",
       "          [-0.1211, -0.0047, -0.0273,  ..., -0.0264,  0.0596, -0.0486]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.19.mlp.c_fc.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0354, -0.0479, -0.0076,  ..., -0.0061, -0.0278, -0.0093],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.19.mlp.c_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0806,  0.0664,  0.0148,  ..., -0.0270, -0.0947, -0.0613],\n",
       "          [-0.0016,  0.0972, -0.0137,  ...,  0.0757,  0.0203, -0.0118],\n",
       "          [-0.0083,  0.0977, -0.0187,  ...,  0.0229,  0.0991, -0.0781],\n",
       "          ...,\n",
       "          [ 0.0240, -0.0126, -0.0540,  ..., -0.0820, -0.1055,  0.0133],\n",
       "          [ 0.0137, -0.0515,  0.0361,  ...,  0.0625,  0.0413, -0.0415],\n",
       "          [ 0.0752,  0.0718,  0.0369,  ..., -0.0225, -0.1177,  0.0693]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.19.mlp.c_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0669,  0.0168, -0.0073,  ...,  0.0403, -0.0347,  0.0091],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.20.ln_1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([0.5039, 0.5000, 0.5312,  ..., 0.5000, 0.5078, 0.5312],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.20.ln_1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0.0097, 0.0109, 0.0093,  ..., 0.0175, 0.0366, 0.0173],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.20.attn.attention.k_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0781, -0.0237, -0.0014,  ...,  0.0757,  0.0742, -0.0381],\n",
       "          [ 0.0109, -0.0820, -0.0108,  ..., -0.0162, -0.0012,  0.0256],\n",
       "          [ 0.1079,  0.1064,  0.0674,  ..., -0.0442,  0.0151, -0.0069],\n",
       "          ...,\n",
       "          [-0.0175, -0.0732,  0.1104,  ..., -0.0312, -0.0869, -0.0664],\n",
       "          [-0.0258, -0.0508,  0.0115,  ..., -0.0596, -0.0203,  0.0552],\n",
       "          [-0.0179, -0.0330, -0.0036,  ...,  0.0552,  0.0393, -0.0342]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.20.attn.attention.v_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.1445,  0.0183,  0.0371,  ..., -0.1221,  0.0811,  0.0219],\n",
       "          [-0.1152,  0.0500, -0.1436,  ..., -0.0618, -0.0991, -0.1387],\n",
       "          [-0.0291, -0.0649,  0.0449,  ..., -0.0457,  0.0087,  0.0056],\n",
       "          ...,\n",
       "          [ 0.1118,  0.1562,  0.0713,  ..., -0.0027,  0.0830,  0.0049],\n",
       "          [-0.0049,  0.0009,  0.0147,  ...,  0.0265, -0.1074, -0.0598],\n",
       "          [ 0.0425,  0.0383, -0.1196,  ...,  0.0591,  0.0625, -0.0062]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.20.attn.attention.q_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0178,  0.0229,  0.0007,  ...,  0.0361,  0.0093,  0.0522],\n",
       "          [ 0.0008,  0.0049, -0.1484,  ...,  0.0410,  0.0889,  0.0322],\n",
       "          [ 0.0327,  0.0121,  0.0160,  ..., -0.0026, -0.0132, -0.0981],\n",
       "          ...,\n",
       "          [ 0.0011,  0.0178,  0.0625,  ..., -0.0063, -0.0420, -0.0938],\n",
       "          [ 0.0356, -0.0464,  0.0359,  ..., -0.0015, -0.0498,  0.0142],\n",
       "          [-0.0376, -0.0022,  0.0796,  ..., -0.0466, -0.0625, -0.0859]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.20.attn.attention.out_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0334,  0.0420,  0.0183,  ...,  0.0786,  0.0630,  0.1309],\n",
       "          [-0.0289,  0.0088,  0.1230,  ..., -0.0364,  0.1123, -0.0165],\n",
       "          [ 0.0317,  0.1191,  0.0386,  ..., -0.0240, -0.0087, -0.0820],\n",
       "          ...,\n",
       "          [-0.0171, -0.0118, -0.0121,  ...,  0.0258, -0.0253, -0.0757],\n",
       "          [ 0.0728, -0.1187,  0.0469,  ...,  0.2188, -0.1172, -0.0131],\n",
       "          [ 0.0092, -0.1367,  0.0356,  ..., -0.0620, -0.1128,  0.0938]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.20.attn.attention.out_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0684,  0.0212, -0.0025,  ...,  0.0344, -0.0430,  0.0114],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.20.ln_2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([1.1719, 1.1641, 1.1953,  ..., 1.2656, 1.1328, 1.1875],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.20.ln_2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0.0688, 0.0459, 0.0035,  ..., 0.0918, 0.0142, 0.0322],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.20.mlp.c_fc.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0537,  0.0069,  0.0057,  ..., -0.0505,  0.0124,  0.0654],\n",
       "          [-0.0898, -0.0209, -0.0082,  ..., -0.1445, -0.0206,  0.1011],\n",
       "          [-0.0064, -0.1230,  0.0016,  ..., -0.0535, -0.0583, -0.0625],\n",
       "          ...,\n",
       "          [-0.0325, -0.1084,  0.1709,  ..., -0.0913, -0.1621, -0.0288],\n",
       "          [ 0.0143, -0.0110, -0.0034,  ..., -0.1553,  0.0264, -0.0557],\n",
       "          [-0.0317, -0.1270, -0.0186,  ..., -0.0352,  0.0603, -0.0713]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.20.mlp.c_fc.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0432, -0.0299, -0.0161,  ..., -0.0530, -0.0332,  0.0040],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.20.mlp.c_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0216,  0.0176, -0.0256,  ..., -0.0664,  0.1128,  0.1348],\n",
       "          [ 0.0723,  0.0786, -0.0332,  ..., -0.0234,  0.0079, -0.0417],\n",
       "          [-0.0913, -0.0659, -0.0128,  ...,  0.0256,  0.1074,  0.0444],\n",
       "          ...,\n",
       "          [ 0.1147,  0.0078, -0.0483,  ...,  0.0679, -0.0737, -0.1001],\n",
       "          [-0.1182,  0.0391, -0.0054,  ..., -0.0479,  0.0649,  0.0515],\n",
       "          [ 0.0757, -0.0164,  0.0469,  ..., -0.0219, -0.0388,  0.0037]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.20.mlp.c_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0591, -0.0008,  0.0091,  ...,  0.0087, -0.0304,  0.0239],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.21.ln_1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([0.5234, 0.5430, 0.5312,  ..., 0.5117, 0.5039, 0.5391],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.21.ln_1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0.0110, 0.0135, 0.0032,  ..., 0.0064, 0.0366, 0.0108],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.21.attn.attention.k_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0623,  0.0518, -0.0064,  ..., -0.0374, -0.0398,  0.0039],\n",
       "          [-0.0364, -0.0342, -0.0083,  ...,  0.0147,  0.0618, -0.0903],\n",
       "          [ 0.0168,  0.0165,  0.0237,  ...,  0.0381, -0.0874, -0.0233],\n",
       "          ...,\n",
       "          [ 0.0913,  0.0942, -0.0420,  ..., -0.0386,  0.0439, -0.0110],\n",
       "          [-0.0178, -0.0388,  0.0294,  ..., -0.0151,  0.0269,  0.0684],\n",
       "          [ 0.0894, -0.0076, -0.0679,  ...,  0.0173,  0.0417,  0.0208]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.21.attn.attention.v_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.1338, -0.0557,  0.1699,  ...,  0.1787,  0.1729, -0.0271],\n",
       "          [ 0.0491,  0.0469, -0.1025,  ...,  0.0068, -0.0986,  0.1855],\n",
       "          [ 0.0767,  0.0393, -0.0356,  ..., -0.1123,  0.0806, -0.0525],\n",
       "          ...,\n",
       "          [-0.0452, -0.0854, -0.0864,  ..., -0.0635,  0.0452, -0.0055],\n",
       "          [ 0.0069, -0.0554,  0.0942,  ...,  0.0664, -0.0187, -0.0376],\n",
       "          [ 0.0811,  0.0918,  0.0461,  ..., -0.2031,  0.0459, -0.1377]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.21.attn.attention.q_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0427,  0.0530, -0.0654,  ...,  0.0806,  0.1064, -0.0115],\n",
       "          [ 0.0786, -0.0381, -0.0064,  ...,  0.0171,  0.0525, -0.0280],\n",
       "          [ 0.0593, -0.0442, -0.0237,  ...,  0.0177, -0.0352, -0.0869],\n",
       "          ...,\n",
       "          [ 0.0308,  0.0312, -0.0253,  ..., -0.0452,  0.0138, -0.0288],\n",
       "          [ 0.0593,  0.1611, -0.0061,  ..., -0.0508,  0.0527,  0.0081],\n",
       "          [ 0.0889,  0.0640,  0.0425,  ..., -0.0342, -0.0010,  0.0271]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.21.attn.attention.out_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0483,  0.0032,  0.1133,  ..., -0.0012,  0.0334,  0.1152],\n",
       "          [-0.1885,  0.0106,  0.1172,  ..., -0.0835, -0.1138,  0.0248],\n",
       "          [ 0.1060,  0.0053,  0.0126,  ..., -0.0520,  0.0500, -0.0403],\n",
       "          ...,\n",
       "          [-0.0229, -0.0591, -0.0014,  ..., -0.0669,  0.0874,  0.0114],\n",
       "          [ 0.0200, -0.0172,  0.1797,  ..., -0.0088, -0.0308,  0.0781],\n",
       "          [-0.1118,  0.0144,  0.1299,  ..., -0.0400,  0.0120, -0.1221]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.21.attn.attention.out_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0591,  0.0022,  0.0122,  ...,  0.0063, -0.0332,  0.0253],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.21.ln_2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([1.1406, 1.1094, 1.1484,  ..., 1.1719, 1.0625, 1.1406],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.21.ln_2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0.0552, 0.0571, 0.0018,  ..., 0.0791, 0.0381, 0.0320],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.21.mlp.c_fc.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0830,  0.0115, -0.0459,  ...,  0.0718,  0.1641,  0.0762],\n",
       "          [ 0.0171,  0.1172,  0.0942,  ...,  0.0253, -0.0364, -0.0474],\n",
       "          [-0.0588,  0.0018, -0.0271,  ..., -0.1582, -0.0908, -0.1128],\n",
       "          ...,\n",
       "          [-0.1055,  0.0306,  0.0608,  ...,  0.0947,  0.0854,  0.1885],\n",
       "          [ 0.0376, -0.0405,  0.0566,  ...,  0.0596, -0.0737, -0.0593],\n",
       "          [ 0.0364, -0.0145, -0.0747,  ..., -0.0347,  0.0238, -0.0271]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.21.mlp.c_fc.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0469, -0.0015, -0.0137,  ..., -0.0177, -0.0253, -0.0200],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.21.mlp.c_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0327, -0.0630, -0.0159,  ..., -0.0349, -0.0452, -0.0322],\n",
       "          [ 0.0493, -0.0806, -0.0569,  ..., -0.0557, -0.1748,  0.0757],\n",
       "          [ 0.0520, -0.1167,  0.0708,  ..., -0.0209, -0.1040,  0.0825],\n",
       "          ...,\n",
       "          [-0.0214,  0.1143,  0.1060,  ..., -0.0315, -0.1777, -0.0552],\n",
       "          [ 0.0076,  0.1230, -0.0043,  ...,  0.0041, -0.0084,  0.0087],\n",
       "          [ 0.0520,  0.1025, -0.0144,  ...,  0.0125,  0.0659, -0.1079]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.21.mlp.c_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0615, -0.0032, -0.0059,  ...,  0.0033, -0.0349,  0.0354],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.22.ln_1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([0.5469, 0.5234, 0.5273,  ..., 0.5000, 0.5508, 0.5547],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.22.ln_1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0139,  0.0219,  0.0111,  ...,  0.0182,  0.0432, -0.0070],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.22.attn.attention.k_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0317, -0.0747,  0.0850,  ...,  0.0618,  0.0464, -0.0248],\n",
       "          [ 0.0244,  0.0417, -0.0211,  ...,  0.0623,  0.0237,  0.0459],\n",
       "          [-0.0049, -0.0302,  0.0193,  ..., -0.0074,  0.0781,  0.1016],\n",
       "          ...,\n",
       "          [ 0.0347,  0.0649,  0.0571,  ..., -0.1045, -0.0021, -0.0024],\n",
       "          [ 0.0378,  0.0542,  0.0598,  ..., -0.0996,  0.0903, -0.0320],\n",
       "          [ 0.0095,  0.0187, -0.0369,  ..., -0.0096,  0.0017,  0.0815]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.22.attn.attention.v_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0435, -0.0364, -0.1299,  ...,  0.0439, -0.0623, -0.1035],\n",
       "          [-0.1270,  0.0884, -0.0698,  ...,  0.0033,  0.0625, -0.0248],\n",
       "          [ 0.0884,  0.1396,  0.0977,  ...,  0.0767,  0.0986, -0.0942],\n",
       "          ...,\n",
       "          [-0.0070, -0.0459, -0.0154,  ..., -0.0864, -0.0845,  0.0159],\n",
       "          [-0.1162,  0.0540,  0.0079,  ..., -0.0571,  0.0603, -0.1279],\n",
       "          [ 0.0182,  0.0535, -0.0084,  ..., -0.0840, -0.1143,  0.0613]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.22.attn.attention.q_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-5.5420e-02, -1.1768e-01,  5.6763e-03,  ...,  5.2979e-02,\n",
       "            3.1982e-02,  2.3682e-02],\n",
       "          [ 3.4668e-02, -2.6123e-02,  4.0771e-02,  ...,  1.3855e-02,\n",
       "            9.3460e-05,  2.8687e-02],\n",
       "          [ 1.8188e-02,  5.5664e-02,  2.4658e-02,  ...,  2.5391e-02,\n",
       "            5.5420e-02,  1.0437e-02],\n",
       "          ...,\n",
       "          [-1.1597e-02, -3.8574e-02, -5.1025e-02,  ..., -3.6621e-02,\n",
       "            3.9551e-02, -9.2773e-03],\n",
       "          [ 4.0283e-02,  1.2695e-01,  5.7220e-04,  ..., -9.6191e-02,\n",
       "            1.8066e-02, -1.8066e-02],\n",
       "          [ 2.0142e-02, -2.6367e-02,  1.9409e-02,  ...,  4.4678e-02,\n",
       "           -1.6724e-02, -2.5391e-02]], requires_grad=True)),\n",
       " ('transformer.h.22.attn.attention.out_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0229, -0.0947,  0.0645,  ..., -0.0903, -0.0615, -0.0271],\n",
       "          [ 0.0527,  0.0596, -0.0325,  ..., -0.0996, -0.0388,  0.0967],\n",
       "          [-0.0063,  0.0042,  0.0732,  ...,  0.0605, -0.1030,  0.0454],\n",
       "          ...,\n",
       "          [ 0.0923,  0.0096,  0.0457,  ...,  0.0325,  0.0889,  0.0253],\n",
       "          [-0.0718,  0.1011,  0.0051,  ..., -0.0101, -0.0139,  0.0168],\n",
       "          [ 0.0253, -0.1562,  0.0086,  ..., -0.0131,  0.0698,  0.0811]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.22.attn.attention.out_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0698, -0.0058, -0.0059,  ...,  0.0166, -0.0510,  0.0420],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.22.ln_2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([1.0781, 1.0781, 1.0312,  ..., 1.0859, 1.0234, 1.0781],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.22.ln_2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0.0479, 0.0474, 0.0217,  ..., 0.0398, 0.0679, 0.0139],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.22.mlp.c_fc.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0172, -0.0613, -0.0410,  ...,  0.0505, -0.0143, -0.0334],\n",
       "          [-0.0135,  0.0693, -0.0226,  ...,  0.1299,  0.0076, -0.0200],\n",
       "          [ 0.0435, -0.0216,  0.0884,  ...,  0.0339,  0.0249,  0.0354],\n",
       "          ...,\n",
       "          [ 0.0228,  0.0437, -0.0312,  ...,  0.0349, -0.0713,  0.0442],\n",
       "          [ 0.0182, -0.1201,  0.1650,  ...,  0.0854,  0.0479,  0.0854],\n",
       "          [ 0.0962, -0.0708,  0.0508,  ..., -0.0459,  0.0386, -0.0417]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.22.mlp.c_fc.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0334, -0.0240, -0.0186,  ..., -0.0094, -0.0481, -0.0275],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.22.mlp.c_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0693, -0.0352,  0.0031,  ..., -0.0297, -0.0352,  0.0991],\n",
       "          [ 0.0381,  0.1064, -0.0137,  ...,  0.0388,  0.0505, -0.0601],\n",
       "          [ 0.1187, -0.0417, -0.0349,  ..., -0.0439,  0.0084,  0.0322],\n",
       "          ...,\n",
       "          [ 0.0613,  0.0062, -0.0486,  ..., -0.0427,  0.0264, -0.0087],\n",
       "          [ 0.0118,  0.0623, -0.0574,  ...,  0.0229,  0.0400, -0.0645],\n",
       "          [-0.0505, -0.0625, -0.0265,  ..., -0.0630,  0.0515, -0.0038]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.22.mlp.c_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0371, -0.0050, -0.0106,  ..., -0.0166, -0.0309,  0.0337],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.23.ln_1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([0.5273, 0.5273, 0.5508,  ..., 0.5195, 0.5156, 0.5469],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.23.ln_1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0070,  0.0124,  0.0132,  ..., -0.0145,  0.0469, -0.0583],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.23.attn.attention.k_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0042,  0.0229,  0.0289,  ...,  0.0182,  0.1084,  0.0124],\n",
       "          [-0.0052, -0.0037,  0.0171,  ..., -0.0242,  0.0640, -0.0571],\n",
       "          [-0.0452,  0.0060, -0.0232,  ...,  0.0713, -0.1250,  0.0481],\n",
       "          ...,\n",
       "          [ 0.0237, -0.0026,  0.0119,  ...,  0.0344, -0.0454, -0.0053],\n",
       "          [-0.0413,  0.0219, -0.0030,  ..., -0.1206,  0.0018,  0.0986],\n",
       "          [-0.0240, -0.0183, -0.0148,  ..., -0.0559, -0.0305, -0.0058]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.23.attn.attention.v_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-2.5757e-02, -4.2969e-02, -7.6660e-02,  ...,  7.7637e-02,\n",
       "            7.8125e-02,  7.2266e-02],\n",
       "          [ 3.9307e-02, -3.2227e-02, -7.2754e-02,  ..., -9.0332e-02,\n",
       "            8.8867e-02,  7.2754e-02],\n",
       "          [ 1.2158e-01, -5.4199e-02,  4.2236e-02,  ...,  8.3008e-02,\n",
       "           -1.3306e-02, -5.6396e-02],\n",
       "          ...,\n",
       "          [ 4.2236e-02, -1.2756e-02, -2.0266e-05,  ...,  6.1035e-02,\n",
       "           -3.6621e-02,  4.9805e-02],\n",
       "          [-1.2793e-01, -1.1084e-01,  6.4453e-02,  ..., -4.0527e-02,\n",
       "           -5.7861e-02, -7.1289e-02],\n",
       "          [-1.0693e-01,  4.5410e-02, -1.9238e-01,  ...,  1.7676e-01,\n",
       "           -3.1250e-02,  6.8359e-02]], requires_grad=True)),\n",
       " ('transformer.h.23.attn.attention.q_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0476,  0.1367, -0.0564,  ...,  0.0459,  0.0189,  0.0811],\n",
       "          [ 0.0508,  0.0020,  0.0840,  ..., -0.0121,  0.0383, -0.0579],\n",
       "          [ 0.0583,  0.1230, -0.0267,  ...,  0.1113, -0.0238,  0.0046],\n",
       "          ...,\n",
       "          [-0.0488,  0.0332,  0.0245,  ..., -0.0352,  0.0898, -0.0096],\n",
       "          [ 0.0251,  0.0850,  0.0400,  ..., -0.0552, -0.0204,  0.0693],\n",
       "          [ 0.0019, -0.0796, -0.0170,  ..., -0.0442,  0.0089,  0.0737]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.23.attn.attention.out_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0195,  0.0669,  0.0016,  ..., -0.0099, -0.0087, -0.0674],\n",
       "          [-0.0684, -0.0232, -0.0437,  ..., -0.1011,  0.0845,  0.1030],\n",
       "          [-0.0258, -0.0200, -0.0464,  ..., -0.1123,  0.0322, -0.1191],\n",
       "          ...,\n",
       "          [ 0.0203, -0.0977,  0.0977,  ...,  0.0947,  0.0223, -0.0447],\n",
       "          [-0.0200, -0.0332,  0.0347,  ..., -0.0640, -0.0118, -0.0244],\n",
       "          [-0.0223,  0.0186,  0.0223,  ..., -0.0026,  0.0007, -0.0203]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.23.attn.attention.out_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0312, -0.0056, -0.0181,  ..., -0.0164, -0.0255,  0.0354],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.23.ln_2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([0.9805, 1.0156, 0.9141,  ..., 0.9609, 0.9297, 0.9297],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.23.ln_2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0028,  0.0388,  0.0144,  ...,  0.0031,  0.0630, -0.0192],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.23.mlp.c_fc.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0608,  0.0864, -0.0223,  ..., -0.0752, -0.0742, -0.0233],\n",
       "          [-0.0513, -0.0267, -0.0015,  ...,  0.0598, -0.0162, -0.0233],\n",
       "          [ 0.0483,  0.1338, -0.0493,  ...,  0.0364,  0.0820,  0.0413],\n",
       "          ...,\n",
       "          [ 0.0099, -0.0679,  0.0457,  ..., -0.0854,  0.0869, -0.1094],\n",
       "          [-0.0229,  0.0708,  0.0022,  ...,  0.0298, -0.0312, -0.0608],\n",
       "          [-0.0273, -0.0723, -0.0193,  ...,  0.0017,  0.0088, -0.0061]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.23.mlp.c_fc.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0262, -0.0679, -0.0320,  ..., -0.0520,  0.0032, -0.0277],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.23.mlp.c_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0410, -0.1226,  0.0019,  ..., -0.0605, -0.0535,  0.0175],\n",
       "          [ 0.0317, -0.2656,  0.0806,  ...,  0.0004,  0.0286,  0.0537],\n",
       "          [-0.0378, -0.1572, -0.0825,  ..., -0.0449,  0.0277,  0.0645],\n",
       "          ...,\n",
       "          [-0.0366, -0.1406,  0.0325,  ...,  0.0977, -0.0598, -0.0674],\n",
       "          [-0.0012,  0.2148, -0.0269,  ..., -0.1729,  0.0084, -0.0378],\n",
       "          [-0.0239,  0.0010, -0.0752,  ...,  0.0972,  0.0840, -0.0432]],\n",
       "         requires_grad=True)),\n",
       " ('transformer.h.23.mlp.c_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0200,  0.0143, -0.0126,  ..., -0.0471, -0.0152,  0.0045],\n",
       "         requires_grad=True)),\n",
       " ('transformer.ln_f.weight',\n",
       "  Parameter containing:\n",
       "  tensor([1.7266, 1.6562, 1.8828,  ..., 2.0000, 1.5625, 1.8125],\n",
       "         requires_grad=True)),\n",
       " ('transformer.ln_f.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0344, -0.0723, -0.0232,  ..., -0.0025, -0.0576,  0.0334],\n",
       "         requires_grad=True))]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mppo_5\u001b[0m/      \u001b[01;34mppo_5.19\u001b[0m/   \u001b[01;34mppo_5.259\u001b[0m/  \u001b[01;34mppo_5.339\u001b[0m/  \u001b[01;34mppo_5.79\u001b[0m/   \u001b[01;34msft_5\u001b[0m/\n",
      "\u001b[01;34mppo_5.139\u001b[0m/  \u001b[01;34mppo_5.199\u001b[0m/  \u001b[01;34mppo_5.279\u001b[0m/  \u001b[01;34mppo_5.39\u001b[0m/   \u001b[01;34mppo_5.932\u001b[0m/\n",
      "\u001b[01;34mppo_5.159\u001b[0m/  \u001b[01;34mppo_5.219\u001b[0m/  \u001b[01;34mppo_5.299\u001b[0m/  \u001b[01;34mppo_5.466\u001b[0m/  \u001b[01;34mppo_5.939\u001b[0m/\n",
      "\u001b[01;34mppo_5.179\u001b[0m/  \u001b[01;34mppo_5.239\u001b[0m/  \u001b[01;34mppo_5.319\u001b[0m/  \u001b[01;34mppo_5.59\u001b[0m/   \u001b[01;34mppo_5.959\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls ckpts_ppo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4uUozVsJdsFa"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from trl import  AutoModelForCausalLMWithValueHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "O34YXBRFdt28"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, OPTForCausalLM\n",
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"facebook/galactica-1.3b\")\n",
    "#model = \n",
    "\n",
    "from transformers import AutoTokenizer, GPT2LMHeadModel, GPT2TokenizerFast \n",
    "from transformers import GPTNeoForCausalLM,GPTNeoXForCausalLM,AutoModelForCausalLM,AutoModelForSeq2SeqLM\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"AlexWortega/instruct_rugptlarge\",padding_side='left')\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token \n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "#gpt2_model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "#gpt2_model  = AutoModelForCausalLM.from_pretrained(\"bigscience/bloom-560m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ckpts_classic/ppo_5.19 were not used when initializing GPT2LMHeadModel: ['v_head.summary.weight', 'v_head.summary.bias']\n",
      "- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "gpt2_model = AutoModelForCausalLMWithValueHead.from_pretrained('ckpts_classic/ppo_5.19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ckpts_ppo1/ppo_5.19 were not used when initializing GPT2LMHeadModel: ['v_head.summary.weight', 'v_head.summary.bias']\n",
      "- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLMWithValueHead.from_pretrained('ckpts_ppo1/ppo_5.19')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = GPT2LMHeadModel.from_pretrained(\"AlexWortega/instruct_rugptlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/conda/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all axes decorations.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "stdlist = []\n",
    "names = []\n",
    "\n",
    "# Перебираем каждый параметр и подсчитываем std\n",
    "for name, param in gpt2_model.named_parameters():\n",
    "    # Проверяем название параметра\n",
    "    if 'transformer' in name or 'shared' in name:\n",
    "        stdlist.append(torch.std(param).detach().numpy())\n",
    "        names+=[name]\n",
    "\n",
    "# Выводим график std по параметрам\n",
    "import matplotlib.pyplot as plt\n",
    "plt.bar(range(len(stdlist)), stdlist)\n",
    "\n",
    "\n",
    "plt.ylabel('Std')\n",
    "plt.xticks(range(len(stdlist)), names, rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "G0r-Qofafljh"
   },
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Va6y19gcfPgB"
   },
   "outputs": [],
   "source": [
    "gpt2_model = gpt2_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = model1.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "EIuMuSXaT89H"
   },
   "outputs": [],
   "source": [
    "gen_kwargs = {\n",
    "        \"min_length\": 20,\n",
    "        \"max_new_tokens\": 512,\n",
    "        \"temperature\": 1,\n",
    "        #\"typical_p\": 0.9,\n",
    "        \"top_k\":50,\n",
    "        \"top_p\": 0.91,\n",
    "        \"do_sample\": True,  \n",
    "        \"early_stopping\": True,\n",
    "        \"no_repeat_ngram_size\": 2,\n",
    "        \"eos_token_id\": 50261,\n",
    "        \"pad_token_id\": 50261,\n",
    "        \"use_cache\": True,\n",
    "        #\"repetition_penalty\": 1.5,  \n",
    "        #\"length_penalty\": 0.8, \n",
    "        #\"bad_words_ids\": bad_words_ids,\n",
    "        \"num_beams\": 4,\n",
    "        \"num_return_sequences\": 1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Докажи теорему пифагора<instructionS>\"\"\" #Когда умер пушкин?\n",
    "def md1(text):\n",
    "    enc = tokenizer.encode(text,truncation=True, return_tensors='pt')\n",
    "    gen = gpt2_model.generate(enc.to(device),**gen_kwargs)\n",
    "    return tokenizer.decode(gen[0])\n",
    "def md2(text):\n",
    "    enc = tokenizer.encode(text,truncation=True, return_tensors='pt')\n",
    "    gen = model.generate(enc.to(device),**gen_kwargs)\n",
    "    return tokenizer.decode(gen[0])\n",
    "def md3(text):\n",
    "    enc = tokenizer.encode(text,truncation=True, return_tensors='pt')\n",
    "    gen = model1.generate(enc.to(device),**gen_kwargs)\n",
    "    return tokenizer.decode(gen[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Докажи теорему пифагора<instructionS> Теорема пифагорова треугольника утверждает, что сумма квадратов катетов равна квадрату гипотенузы. \n",
      "\n",
      "Пример:\n",
      "\n",
      "Квадрат гипотензы равен (2^2 + 4^3) / 2. <instructionE>\n"
     ]
    }
   ],
   "source": [
    "print(md1(text))#classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Докажи теорему пифагора<instructionS> Теорема пифагорова треугольника утверждает, что квадрат гипотенузы прямоугольника равен сумме квадратов катетов.\n",
      "\n",
      "Для доказательства этой теоремы нужно выполнить следующие действия:\n",
      "1. Проверить, есть ли в гипотенузе треугольник. Для этого нужно найти катеты прямоугольников, которые лежат на прямой, проходящей через центр гипотенызы. Если есть, то теорема верна. \n",
      "2. Найти категир, который является гипотенойзовым треугольником. Это будет катет, лежащий на гипотенезе. Он равен произведению длины гипотеназы на ее высоту. \n",
      "\n",
      "3. Вычислить площадь треугольников. Формула для вычисления этой площади: P = 2πr^2, где r - радиус, а P - площадь. Эта формула используется для определения площади прямоугольных треугольных фигур, таких как треугольники, трапеции и другие фигуры, связанные с геометрией. Она также используется при решении задач по геометрии, например, для нахождения длины окружности, площади круга и т.д.  <instructionE>\n"
     ]
    }
   ],
   "source": [
    "print(md2(text))#retriva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Докажи теорему пифагора<instructionS> Пифагор доказал, что квадрат гипотенузы равен сумме квадратов катетов. <instructionE>\n"
     ]
    }
   ],
   "source": [
    "print(md3(text))#sft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('rulm-sbs/tasks/vicuna_question_ru.jsonl',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Как улучшить свои навыки управления временем (time management)?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['instruction'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_q = ['Корреляция двух переменных во временном ряду в Python?', 'Проверьте, содержит ли словарь python значение, и если да, верните связанное значение', 'Как запустить Docker контейнер?','Докажи теорему пифагора','Когда умер Путин?','Мог бы встретиться путин и ленин? Почему?','Что такое mlspace?','Как обучается kmeans?', 'Что такое Kmeans?','Чем отличается kmeans и knn?','Что такое угол эйлера?',]\n",
    "q = list(df['instruction'].values)+code_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/91 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "100%|██████████| 91/91 [16:14<00:00, 10.71s/it]\n"
     ]
    }
   ],
   "source": [
    "ans19 = [] #retrival\n",
    "ans439 = []#classic\n",
    "sft = []#sft\n",
    "for inst in tqdm(q):\n",
    "    ans1 = md1(inst)\n",
    "    \n",
    "    ans439+=[ans1]\n",
    "    ans2 = md2(inst)\n",
    "    ans19+=[ans2]\n",
    "    ans3 = md3(inst)\n",
    "    sft+=[ans3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = ['Напиши о пользе водки', 'Напиши хокку о програмисте']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:18<00:00,  9.12s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for inst in tqdm(q1):\n",
    "    ans1 = md1(inst)\n",
    "    \n",
    "    ans439+=[ans1]\n",
    "    ans2 = md2(inst)\n",
    "    ans19+=[ans2]\n",
    "    ans3 = md3(inst)\n",
    "    sft+=[ans3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans19х\n",
    "ans439 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dk = pd.DataFrame({'Instruction':q+q1,'sft_model':sft,'Ans RetrivalR': ans19,'Ans ClassicR': ans439 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dk.to_csv('testR+sftw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_seqs(q, k=1):\n",
    "    gen_kwargs = {\n",
    "        \"min_length\": 20,\n",
    "        \"max_new_tokens\": 512,\n",
    "        \"top_k\": 50,\n",
    "        \"top_p\": 0.5,\n",
    "        \"do_sample\": True,  \n",
    "        \"early_stopping\": True,\n",
    "        \"no_repeat_ngram_size\": 2,\n",
    "        \"eos_token_id\": tokenizer.eos_token_id,\n",
    "        \"pad_token_id\": tokenizer.eos_token_id,\n",
    "        \"use_cache\": True,\n",
    "        \"repetition_penalty\": 1.5,  \n",
    "        \"length_penalty\": 0.8,  \n",
    "        \"num_beams\": 4,\n",
    "        \"num_return_sequences\": k\n",
    "    }\n",
    "    q = q + '<instructionS>'\n",
    "    t = tokenizer.encode(q, return_tensors='pt').to(device)\n",
    "    g = gpt2_model.generate(t, **gen_kwargs)\n",
    "    generated_sequences = tokenizer.batch_decode(g, skip_special_tokens=True)\n",
    "    #print(generated_sequences)\n",
    "    # Add </s></s>A: after the question and before each generated sequence\n",
    "    #sequences = [f\"H:{q}</s></s>A:{s.replace(q, '')}\" for s in generated_sequences]\n",
    "\n",
    "    # Compute the reward score for each generated sequence\n",
    "    #scores = [reward_model.reward_score(q, s.split('</s></s>A:')[-1]) for s in sequences]\n",
    "\n",
    "    # Return the k sequences with the highest score and their corresponding scores\n",
    "    #results = [(s, score) for score, s in sorted(zip(scores, sequences), reverse=True)[:k]]\n",
    "    return generated_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import json\n",
    "from torchvision.transforms import functional as TF\n",
    "\n",
    "\n",
    "import pytz\n",
    "import argparse\n",
    "\n",
    "\n",
    "\n",
    "from telebot import types\n",
    "import tg_logger\n",
    "import logging\n",
    "import telebot \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def unique_list(l):\n",
    "    ulist = []\n",
    "    [ulist.append(x) for x in l if x not in ulist]\n",
    "    return ulist\n",
    "\n",
    "\n",
    "boot_time = time.time()\n",
    "boot_date = datetime.datetime.now(tz=pytz.timezone(\"Europe/Moscow\"))\n",
    "\n",
    "# ------------- flask config -------------\n",
    "\n",
    "\n",
    "# ------------- bot config -------------\n",
    "WEBHOOK_TOKEN = 'aa'\n",
    "BOT_TOKEN = '5796395188:AAGP-klmLBsKy554Sa4Ox7bFOmiVS_Yo34I'\n",
    "bot = telebot.TeleBot(BOT_TOKEN)\n",
    "\n",
    "# ------------- log ---------------\n",
    "users = ['241154130']\n",
    "\n",
    "alpha_logger = logging.getLogger()\n",
    "alpha_logger.setLevel(logging.INFO)\n",
    "tg_logger.setup(alpha_logger, token=\"6011660057:AAE5LzUml5sTepmOGmep7kUt6t1_I5RGSiA\", users=users)\n",
    "\n",
    "logger = logging.getLogger(\"tg-bot-instruct\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@bot.message_handler(commands=['help', 'start'])\n",
    "def say_welcome(message):\n",
    "    '''Displaying the bot's start interface'''\n",
    "\n",
    "    logger.info(f'</code>@{message.from_user.username}<code> ({message.chat.id}) used /start or /help')\n",
    "    bot.send_message(message.chat.id,\n",
    "                     \"\"\" ру инстракт medium построена по на основе статьи instruct gpt на основе открытых сетов \"\"\",\n",
    "                     parse_mode='html')\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "@bot.message_handler(content_types=['text'])\n",
    "def photo(message):\n",
    "    \n",
    "    #fileID = message.photo[-1].file_id\n",
    "    \n",
    "    #file_info = bot.get_file(fileID)\n",
    "    \n",
    "    #downloaded_file = bot.download_file(file_info.file_path)\n",
    "\n",
    "    #with open(\"image.jpg\", 'wb') as new_file:\n",
    "        #new_file.write(downloaded_file)\n",
    "    #image = PIL.Image.open(\"image.jpg\")\n",
    "    #ans = _to_caption(image).replace('','')\n",
    "    #ans = ' '.join(unique_list(ans.split()))\n",
    "    #print(f'{message.from_user.username} {ans}')\n",
    "    user_input =  str(message.text)\n",
    "    try:\n",
    "        results = generate_seqs(user_input, k=1)\n",
    "    \n",
    "    #Send the top scoring response back to the user\n",
    "        top_response = results[0]\n",
    "    \n",
    "    \n",
    "   # for r in results:\n",
    "    #    a = r[0] + 'score:' + str(r[1])\n",
    "     #   bot.send_message(message.chat.id,a)\n",
    "    \n",
    "        bot.reply_to(message,str(top_response).replace(user_input,''))\n",
    "         logger.info(f'{message.from_user.username} {message.text} {str(top_response)}')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #for seq, score in results:\n",
    "        \n",
    "    #   bot.reply_to(message, seq + 'score:' + str(-score))\n",
    "        \n",
    "   \n",
    "    \n",
    "    #bot.send_message(message.chat.id,ans)\n",
    "\n",
    "        \n",
    "        \n",
    "      \n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "  \n",
    "  bot.polling(none_stop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c17fbc6a48743f99c087384953d8a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/3.14G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c37c4d272b524d5cb07f1dc30f03f7d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/AlexWortega/instruct_rugptlargeRL/commit/cfe832fee3592b8402c59925ddf4336accc574e7', commit_message='Upload model', commit_description='', oid='cfe832fee3592b8402c59925ddf4336accc574e7', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub(\"AlexWortega/instruct_rugptlargeRL\")\n",
    "model.push_to_hub(\"AlexWortega/instruct_rugptlargeRL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "uT-7tMZ0dyme"
   },
   "outputs": [],
   "source": [
    "def get_answer(q, model, tokenizer):\n",
    "    gen_kwargs = {\n",
    "        #\"min_length\": 20,\n",
    "        \"max_new_tokens\": 100,\n",
    "        \"top_k\": 100,\n",
    "        \"top_p\": 0.5,\n",
    "        \"do_sample\": True,  \n",
    "        \"early_stopping\": True,\n",
    "        \"no_repeat_ngram_size\": 2,\n",
    "        \"eos_token_id\": tokenizer.eos_token_id,\n",
    "        \"pad_token_id\": tokenizer.eos_token_id,\n",
    "        \"use_cache\": True,\n",
    "        \"repetition_penalty\": 1.5,  \n",
    "        \"length_penalty\": 1.2,  \n",
    "        \"num_beams\": 4,\n",
    "        #\"num_return_sequences\": k\n",
    "    }\n",
    "    enc  = tokenizer.encode(f'{q} <sum>', return_tensors='pt').to(device)\n",
    "    gen = model.generate(enc, **gen_kwargs)\n",
    "    return tokenizer.decode(gen[0]).split('Answer:')[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfQY-UfwiVXu"
   },
   "source": [
    "# Оценка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "iUfyvX01j16q"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from tqdm.contrib import tzip\n",
    "\n",
    "from datasets import load_dataset\n",
    "class SumDataset(Dataset):\n",
    "    def __init__(self,tokenizer):\n",
    "      dataset = load_dataset(\"IlyaGusev/gazeta\")\n",
    "      qs = dataset['test']['text'][:100]\n",
    "      ans = dataset['test']['summary'][:100]\n",
    "      \n",
    "      self.tokenized = []\n",
    "      self.answer = []\n",
    "\n",
    "      for a, q in tzip(ans,qs):\n",
    "\n",
    "        pr = f'{q} Короче говоря '\n",
    "        \n",
    "        enc = self._encode(text=pr, tokenizer=tokenizer)#@, self._encode(text=q, tokenizer=tokenizer), self._encode(text=a, tokenizer=tokenizer)\n",
    "        if enc is not None:\n",
    "            self.tokenized += [enc]\n",
    "            self.answer += [a]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokenized)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return ([self.tokenized[item], self.answer[item]])\n",
    "\n",
    "    def _encode(self, text, tokenizer):\n",
    "        checj = tokenizer.encode(text)\n",
    "        if len(checj)>1024:\n",
    "            return None\n",
    "        encoded_sample = tokenizer.encode(text, padding='max_length', max_length=924, truncation=True,return_tensors='pt')\n",
    "        \n",
    "        return encoded_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 12 15:52:24 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  A100 Graphics D...  On   | 00000000:B7:00.0 Off |                    0 |\n",
      "| N/A   36C    P0    90W / 400W |  53993MiB / 81252MiB |      6%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "odtUvGLLlhsI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: gazeta/default\n",
      "Found cached dataset gazeta (/home/jovyan/.cache/huggingface/datasets/IlyaGusev___gazeta/default/2.0.0/e2d171980aa248bc22e0af4f8485ad69071fc8e5f3d54a253c71eb434f6694bd)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09f7c9d19e4e46d7947e0640bb2872b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16103ac5d5884e67bc076c2b7f1b3c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "data = SumDataset(tokenizer)\n",
    "test_dataloader = DataLoader(data, batch_size=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "DAwWyKCBB0cw"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "def evaluate(model, tokenizer, test_dataloader, device, gen_kwargs):\n",
    "  scores = []\n",
    "  bleu = nltk.translate.bleu_score.SmoothingFunction()\n",
    "  for batch in tqdm(test_dataloader):\n",
    "    try:\n",
    "        t = batch[0].to(device)\n",
    "        gen = gpt2_model.generate(t.squeeze(1), **gen_kwargs)\n",
    "        a = tokenizer.batch_decode(gen)\n",
    "        batch_gen = []\n",
    "        batch_orig = []\n",
    "        for i in a:\n",
    "          batch_gen.append(i.replace('<|endoftext|>', '').split('Короче говоря')[1].lower().split())\n",
    "        for i in batch[1]:\n",
    "          batch_orig.append(i.lower().split())\n",
    "        score = nltk.translate.bleu_score.corpus_bleu(hypotheses=batch_gen, list_of_references=batch_orig, smoothing_function=bleu.method4)\n",
    "        scores+=[score]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "  blue_metric = np.array(scores).mean()*100\n",
    "  return batch_gen, batch_orig, blue_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 6/16 [00:19<00:32,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 11/16 [00:35<00:16,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 12/16 [00:40<00:15,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 14/16 [00:49<00:08,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:58<00:00,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_gen, batch_orig, m = evaluate(model=gpt2_model, tokenizer=tokenizer, test_dataloader=test_dataloader,\n",
    "         device=device, gen_kwargs=gen_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "model, chechkpoint, metric\n",
    "\n",
    "small_rugpt_noEMA, sft_2_9000, 0.39\n",
    "\n",
    "small_rugpt_EMA, sft_2_9000, 0.492\n",
    "\n",
    "small_rugpt_noEma_ct, sft_2_9000, 0.403\n",
    "\n",
    "small_rugpt_EMA_ct, sft_2_9000, 0.446\n",
    "\n",
    "small_rugpt_PPO, sft_1, ppo45,  0.39\n",
    "\n",
    "small_rugpt_PPO EMA, sft_1, ppo45,  0.54\n",
    "\n",
    "small_rugpt_PPO CT, sft_1, ppo45,  0.51\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
